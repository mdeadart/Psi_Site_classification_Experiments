{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Define all parameters for model tuning\n",
    "##################################################################################\n",
    "\n",
    "n_fold = 5\n",
    "expName = \"PSI_Site_DLNN_conv2D\"\n",
    "outPath = \"Results\"\n",
    "foldName = \"folds.pickle\"\n",
    "\n",
    "input_data_folder = \"Data\\\\Aziz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from Bio import SeqIO\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# print(tf.test.is_gpu_available(cuda_only=True))\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define all CUSTOM functions\n",
    "##################################################################################\n",
    "\n",
    "def one_hot_encode_dna(sequence):\n",
    "    seq_encoded = np.zeros((len(sequence),4))\n",
    "    dict_nuc = {\n",
    "        \"A\": 0,\n",
    "        \"C\": 1,\n",
    "        \"G\": 2,\n",
    "        \"T\": 3\n",
    "    }\n",
    "    i = 0\n",
    "    for single_character in sequence:\n",
    "        if(single_character.upper() in dict_nuc.keys()):\n",
    "            seq_encoded[i][dict_nuc[single_character.upper()]] = 1\n",
    "            i = i+1\n",
    "        else:\n",
    "            raise ValueError('Incorrect character in DNA sequence: '+sequence)\n",
    "    return seq_encoded\n",
    "\n",
    "def one_hot_encode_rna(sequence):\n",
    "    seq_encoded = np.zeros((len(sequence),4))\n",
    "    dict_nuc = {\n",
    "        \"A\": 0,\n",
    "        \"C\": 1,\n",
    "        \"G\": 2,\n",
    "        \"U\": 3\n",
    "    }\n",
    "    i = 0\n",
    "    for single_character in sequence:\n",
    "        if(single_character.upper() in dict_nuc.keys()):\n",
    "            seq_encoded[i][dict_nuc[single_character.upper()]] = 1\n",
    "            i = i+1\n",
    "        else:\n",
    "            raise ValueError('Incorrect character in RNA sequence: '+sequence)\n",
    "    return seq_encoded\n",
    "\n",
    "def one_hot_encode_rnafold(sequence):\n",
    "    seq_encoded = np.zeros((len(sequence),3))\n",
    "    dict_fold = {\n",
    "        \"(\": 0,\n",
    "        \")\": 1,\n",
    "        \".\": 2\n",
    "    }\n",
    "    i = 0\n",
    "    for single_character in sequence:\n",
    "        if(single_character in dict_fold.keys()):\n",
    "            seq_encoded[i][dict_fold[single_character]] = 1\n",
    "            i = i+1\n",
    "        else:\n",
    "            raise ValueError('Incorrect character in RNAfold: '+sequence)\n",
    "    return seq_encoded\n",
    "\n",
    "def one_hot_encode_rna_mergedseq(sequence):\n",
    "    dict_nuc = {\n",
    "        \"A\": 0,\n",
    "        \"C\": 1,\n",
    "        \"G\": 2,\n",
    "        \"U\": 3\n",
    "    }\n",
    "    dict_fold = {\n",
    "        \"(\": 0,\n",
    "        \")\": 1,\n",
    "        \".\": 2\n",
    "    }\n",
    "    list_seq = sequence.strip().split(' ')\n",
    "    seq_encoded = np.zeros((len(list_seq),12))\n",
    "    i = 0\n",
    "    for single_character in list_seq:\n",
    "        if(single_character[0].upper() in dict_nuc.keys()):\n",
    "            idx1 = dict_nuc[single_character[0].upper()]+1\n",
    "        else:\n",
    "            raise ValueError('Incorrect RNA character in MergedSeq sequence: '+sequence)\n",
    "        if(single_character[1] in dict_fold.keys()):\n",
    "            idx2 = dict_fold[single_character[1]]+1\n",
    "        else:\n",
    "            raise ValueError('Incorrect RNAfold character in MergedSeq sequence: '+sequence)\n",
    "        idx = (idx1 * idx2) - 1\n",
    "        seq_encoded[i][idx] = 1\n",
    "        i = i+1        \n",
    "    return seq_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define evaluator functions\n",
    "##################################################################################\n",
    "\n",
    "## Build the K-fold from dataset\n",
    "def build_kfold(features, labels, k=10, shuffle=False, seed=None):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "    kfoldList = []\n",
    "    for train_index, test_index in skf.split(features, labels):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        kfoldList.append({\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\":y_train,\n",
    "            \"y_test\":y_test\n",
    "        })\n",
    "    return kfoldList\n",
    "\n",
    "def build_kfold_multifeature(features_1, features_2, labels, k=10, shuffle=False, seed=None):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "    kfoldList = []\n",
    "    for train_index, test_index in skf.split(features_1, labels):\n",
    "        X1_train, X1_test = features_1[train_index], features_1[test_index]\n",
    "        X2_train, X2_test = features_2[train_index], features_2[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        kfoldList.append({\n",
    "            \"X1_train\": X1_train,\n",
    "            \"X1_test\": X1_test,\n",
    "            \"X2_train\": X2_train,\n",
    "            \"X2_test\": X2_test,\n",
    "            \"y_train\":y_train,\n",
    "            \"y_test\":y_test\n",
    "        })\n",
    "    return kfoldList\n",
    "\n",
    "def pred2label(y_pred):\n",
    "    y_pred = np.round(np.clip(y_pred, 0, 1))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# ##### Function to customize the DLNN architecture with parameters\n",
    "# ##################################################################################\n",
    "\n",
    "# def DLNN_MergedSeq_aziz(input_shape = (21,12),\n",
    "#                         conv_filters_per_layer = 9, max_kernel_length = 11, conv_strides = 1, ## 1st Convolutional layer parameters\n",
    "#                         max_pool_width = 2, max_pool_stride = 2, ## 1st Maxpool layer parameters\n",
    "#                         rnn_decode_units = 10, ## LSTM layer parameters\n",
    "#                         dense_decode_units = 1024, ## Dense layer parameters\n",
    "#                         prob = 0.5, learn_rate = 0.0001, loss = 'binary_crossentropy', \n",
    "#                         metrics = None):\n",
    "    \n",
    "#     max_kernel_length = int(np.ceil(input_shape[0]/2))\n",
    "    \n",
    "#     beta = 0.01\n",
    "    \n",
    "#     assert max_kernel_length >= 3\n",
    "    \n",
    "#     input1 = tf.keras.layers.Input(shape=input_shape)\n",
    "    \n",
    "#     ###########################################################################\n",
    "#     ##### Multipath Conv\n",
    "#     ###########################################################################\n",
    "    \n",
    "#     x2 = []\n",
    "#     for kernel_length in range(3, max_kernel_length):\n",
    "#         xxc = tf.keras.layers.Conv1D(conv_filters_per_layer, kernel_length, \n",
    "#                                     strides = conv_strides)(input1)\n",
    "        \n",
    "#         xxc = tf.keras.layers.Activation('relu')(xxc)\n",
    "#         xxc = tf.keras.layers.MaxPool1D(pool_size = max_pool_width, strides = max_pool_stride)(xxc)\n",
    "#         xxc = tf.keras.layers.Flatten()(xxc)\n",
    "#         x2.append(xxc)\n",
    "        \n",
    "#     ###########################################################################\n",
    "#     ##### Fully connected Layers\n",
    "#     ###########################################################################\n",
    "\n",
    "#     y = tf.keras.layers.Concatenate(1)(x2)\n",
    "    \n",
    "#     y = tf.keras.layers.Dense(dense_decode_units)(y)\n",
    "#     y = tf.keras.layers.Activation('relu')(y)\n",
    "#     y = tf.keras.layers.Dropout(prob)(y)\n",
    "    \n",
    "#     y = tf.keras.layers.Dense(dense_decode_units)(y)\n",
    "#     y = tf.keras.layers.Activation('softmax')(y)\n",
    "    \n",
    "#     y = tf.keras.layers.Dense(1, activation = 'sigmoid')(y)\n",
    "    \n",
    "#     #########################\n",
    "#     ##### Generate Model from input and output\n",
    "#     #########################\n",
    "    \n",
    "#     model = tf.keras.models.Model(inputs=[input1], outputs=y)\n",
    "    \n",
    "#     ## Compile model\n",
    "#     if(metrics != None):\n",
    "#         model.compile(optimizer = tf.keras.optimizers.Adam(lr=learn_rate), loss = loss, metrics = metrics)\n",
    "#     else:\n",
    "#         model.compile(optimizer = tf.keras.optimizers.Adam(lr=learn_rate), loss = loss)\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Function to customize the DLNN architecture with parameters\n",
    "##################################################################################\n",
    "\n",
    "def DLNN_MergedSeq_conv2d(input_shape = (31,12,1),\n",
    "                        conv_filters_per_layer = 3, max_kernel_length = 11, conv_strides = 1, ## 1st Convolutional layer parameters\n",
    "                        max_pool_width = 2, max_pool_stride = 2, ## 1st Maxpool layer parameters\n",
    "                        rnn_decode_units = 10, ## LSTM layer parameters\n",
    "                        dense_decode_units = 256, ## Dense layer parameters\n",
    "                        prob = 0.5, learn_rate = 0.001, loss = 'binary_crossentropy', \n",
    "                        metrics = None):\n",
    "    \n",
    "    # max_kernel_length = int(np.ceil(input_shape[0]/2))\n",
    "    \n",
    "    beta = 0.00001\n",
    "    \n",
    "    assert max_kernel_length >= 3\n",
    "    \n",
    "    input1 = tf.keras.layers.Input(shape=input_shape)\n",
    "    \n",
    "    ###########################################################################\n",
    "    ##### Multipath Conv\n",
    "    ###########################################################################\n",
    "    \n",
    "    x2 = []\n",
    "    for kernel_length in range(3, 10, 2):\n",
    "        xxc = tf.keras.layers.Conv2D(conv_filters_per_layer, kernel_length, \n",
    "                                    strides = conv_strides)(input1)\n",
    "        \n",
    "        xxc = tf.keras.layers.Activation('relu')(xxc)\n",
    "        xxc = tf.keras.layers.MaxPool2D(pool_size = max_pool_width, strides = max_pool_stride)(xxc)\n",
    "        xxc = tf.keras.layers.Flatten()(xxc)\n",
    "        x2.append(xxc)\n",
    "        \n",
    "    ###########################################################################\n",
    "    ##### Fully connected Layers\n",
    "    ###########################################################################\n",
    "\n",
    "    y = tf.keras.layers.Concatenate(1)(x2)\n",
    "    \n",
    "    y = tf.keras.layers.Dense(dense_decode_units)(y)\n",
    "    y = tf.keras.layers.Activation('relu')(y)\n",
    "    # y = tf.keras.layers.Dropout(prob)(y)\n",
    "    \n",
    "    y = tf.keras.layers.Dense(dense_decode_units)(y)\n",
    "    y = tf.keras.layers.Activation('softmax')(y)\n",
    "    \n",
    "    y = tf.keras.layers.Dense(1, activation = 'sigmoid')(y)\n",
    "    \n",
    "    #########################\n",
    "    ##### Generate Model from input and output\n",
    "    #########################\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[input1], outputs=y)\n",
    "    \n",
    "    ## Compile model\n",
    "    if(metrics != None):\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr=learn_rate), loss = loss, metrics = metrics)\n",
    "    else:\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(lr=learn_rate), loss = loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 31, 12, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 29, 10, 3)    30          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 27, 8, 3)     78          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 25, 6, 3)     150         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 23, 4, 3)     246         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 29, 10, 3)    0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 27, 8, 3)     0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 25, 6, 3)     0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 23, 4, 3)     0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 14, 5, 3)     0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 13, 4, 3)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 12, 3, 3)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 11, 2, 3)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 210)          0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 156)          0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 108)          0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 66)           0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 540)          0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          138496      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         activation_5[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 205,049\n",
      "Trainable params: 205,049\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DLNN_MergedSeq_conv2d().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_model_evaluation(lr_rate: 0.001, \n",
    "                             epochs = 100,\n",
    "                             batch_size = 32,\n",
    "                             shuffle = True\n",
    "                            ):\n",
    "    ##################################################################################\n",
    "    ##### For each input file, train model and generate different outputs in a structured folder\n",
    "    ##################################################################################\n",
    "\n",
    "    ## create the evaluation data structure for all iterations\n",
    "    evaluations = {\n",
    "        \"Model\" : [],\n",
    "        \"Kernel_Length\" : [],\n",
    "        \"Dataset\" : [],\n",
    "        \"Fold\" : [],\n",
    "        \"Train_Test\" : [],\n",
    "        \"Accuracy\" : [],\n",
    "        \"Precision\": [],\n",
    "        \"TPR\": [],\n",
    "        \"FPR\": [],\n",
    "        \"TPR_FPR_Thresholds\": [],\n",
    "        \"AUC\": [],\n",
    "        \"Sensitivity\": [],\n",
    "        \"Specificity\": [],\n",
    "        \"MCC\":[]\n",
    "    }\n",
    "\n",
    "    for root, dirs, files in os.walk(input_data_folder):\n",
    "        for file in files:\n",
    "\n",
    "            input_data_file = os.path.join(root, file)\n",
    "\n",
    "            current_dataset_variety = input_data_file.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "            csv_data = pd.read_csv(input_data_file)\n",
    "\n",
    "            ##################################################################################\n",
    "            ##### extract data from the current CSV file\n",
    "            ##################################################################################\n",
    "\n",
    "            csv_data[\"OHE_MergedSeq\"] = pd.Series([one_hot_encode_rna_mergedseq(val) for val in csv_data[\"MergedSeq\"]])\n",
    "\n",
    "            df_positive = csv_data[csv_data['Number'].str.contains(\"P\")]\n",
    "            df_negative = csv_data[csv_data['Number'].str.contains(\"N\")]\n",
    "\n",
    "            positive_onehotencoded_array = np.array(list(df_positive['OHE_MergedSeq']))\n",
    "            negative_onehotencoded_array = np.array(list(df_negative['OHE_MergedSeq']))\n",
    "\n",
    "            print(\"\\n======================================================================\")\n",
    "            print(\"\\nFile:\", input_data_file)\n",
    "            print(\"Positive:\", positive_onehotencoded_array.shape[0])\n",
    "            print(\"Negative:\", negative_onehotencoded_array.shape[0])\n",
    "\n",
    "            ##################################################################################\n",
    "            ##### Generate Folds from dataset, and store to file\n",
    "            ##################################################################################\n",
    "\n",
    "            ## create the features and labels datasets for the training\n",
    "            input_size = positive_onehotencoded_array[0].shape\n",
    "\n",
    "            labels = np.concatenate((np.ones((positive_onehotencoded_array.shape[0], 1), \n",
    "                                             dtype=np.float32), \n",
    "                                     np.zeros((negative_onehotencoded_array.shape[0], 1), \n",
    "                                              dtype=np.float32)), \n",
    "                                    axis=0)\n",
    "\n",
    "            features = np.concatenate((positive_onehotencoded_array, \n",
    "                                       negative_onehotencoded_array), \n",
    "                                      axis=0)\n",
    "            features_required_shape = tuple(list(features.shape) + [1])\n",
    "            features = features.reshape(features_required_shape)\n",
    "            model_input_shape = tuple(list(features.shape[1:]))\n",
    "\n",
    "            folds = build_kfold(features, labels, \n",
    "                                k=n_fold, shuffle=shuffle, seed=seed)\n",
    "\n",
    "            ## Write the k-fold dataset to file\n",
    "            foldPath = os.path.join(outPath, expName, current_dataset_variety, \"{}fold\".format(n_fold))\n",
    "            if(not os.path.isdir(foldPath)):\n",
    "                os.makedirs(foldPath)\n",
    "            pickle.dump(folds, open(os.path.join(foldPath, foldName), \"wb\"))\n",
    "\n",
    "            ## Create and set directory to save model\n",
    "            modelPath = os.path.join(outPath, expName, current_dataset_variety, \"{}fold\".format(n_fold), \"models\")\n",
    "            if(not os.path.isdir(modelPath)):\n",
    "                os.makedirs(modelPath)\n",
    "\n",
    "            ##################################################################################\n",
    "            ##### TRAIN and PREDICT for every Fold, using models\n",
    "            ##################################################################################\n",
    "\n",
    "            # fold counter\n",
    "            i = 0\n",
    "\n",
    "            for fold in folds:\n",
    "\n",
    "                print(\"\\nTrain/Test model \"+current_dataset_variety+\" on Fold #\"+str(i)+\".\")\n",
    "\n",
    "                kernel_length = 3\n",
    "                ## Generate model using function\n",
    "            #             model = Conv_LSTM_DLNN(input_shape = input_size, conv_filters_per_layer = 50, kernel_length = kernel_length, \n",
    "            #                                    lstm_decode_units = 50, max_pool_width = 2, max_pool_stride = 2, dense_decode_units = 50,\n",
    "            #                                    learn_rate = 0.0001, prob = 0.5, loss='binary_crossentropy', metrics=None)\n",
    "\n",
    "                model = DLNN_MergedSeq_conv2d(input_shape = model_input_shape, \n",
    "                                              learn_rate = lr_rate\n",
    "                                             )\n",
    "\n",
    "                ## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "            #     modelCallbacks = [\n",
    "            #         tf.keras.callbacks.ModelCheckpoint(os.path.join(modelPath, \"{}_bestModel-fold{}.hdf5\".format(current_dataset_variety, i)),\n",
    "            #                                            monitor = 'val_loss', verbose = 1, save_best_only = True, \n",
    "            #                                            save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "            #         tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 10, verbose = 1, \n",
    "            #                                          mode = 'auto', baseline = None, restore_best_weights = False)\n",
    "            #     ]\n",
    "            #     model.fit(x = fold[\"X_train\"], y = fold[\"y_train\"], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "            #               callbacks = modelCallbacks, validation_split=0.2)\n",
    "\n",
    "                model.fit(x = fold[\"X_train\"], y = fold[\"y_train\"], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "                          validation_split=0.2)\n",
    "\n",
    "                ##################################################################################\n",
    "                ##### Prediction and metrics for TRAIN dataset\n",
    "                ##################################################################################\n",
    "\n",
    "                y_pred = model.predict(fold[\"X_train\"])\n",
    "                label_pred = pred2label(y_pred)\n",
    "                # Compute precision, recall, sensitivity, specifity, mcc\n",
    "                acc = accuracy_score(fold[\"y_train\"], label_pred)\n",
    "                prec = precision_score(fold[\"y_train\"],label_pred)\n",
    "\n",
    "                conf = confusion_matrix(fold[\"y_train\"], label_pred)\n",
    "                if(conf[0][0]+conf[1][0]):\n",
    "                    sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "                else:\n",
    "                    sens = 0.0\n",
    "                if(conf[1][1]+conf[0][1]):\n",
    "                    spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "                else:\n",
    "                    spec = 0.0\n",
    "                if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "                    mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "                else:\n",
    "                    mcc= 0.0\n",
    "                fpr, tpr, thresholds = roc_curve(fold[\"y_train\"], y_pred)\n",
    "                auc = roc_auc_score(fold[\"y_train\"], y_pred)\n",
    "\n",
    "                evaluations[\"Model\"].append(current_dataset_variety)\n",
    "                evaluations[\"Kernel_Length\"].append(kernel_length)\n",
    "                evaluations[\"Dataset\"].append(current_dataset_variety)\n",
    "                evaluations[\"Fold\"].append(i)\n",
    "                evaluations[\"Train_Test\"].append(\"Train\")\n",
    "                evaluations[\"Accuracy\"].append(acc)\n",
    "                evaluations[\"Precision\"].append(prec)\n",
    "                evaluations[\"TPR\"].append(tpr)\n",
    "                evaluations[\"FPR\"].append(fpr)\n",
    "                evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "                evaluations[\"AUC\"].append(auc)\n",
    "                evaluations[\"Sensitivity\"].append(sens)\n",
    "                evaluations[\"Specificity\"].append(spec)\n",
    "                evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "                ##################################################################################\n",
    "                ##### Prediction and metrics for TEST dataset\n",
    "                ##################################################################################\n",
    "\n",
    "                y_pred = model.predict(fold[\"X_test\"])\n",
    "                label_pred = pred2label(y_pred)\n",
    "                # Compute precision, recall, sensitivity, specifity, mcc\n",
    "                acc = accuracy_score(fold[\"y_test\"], label_pred)\n",
    "                prec = precision_score(fold[\"y_test\"],label_pred)\n",
    "\n",
    "                conf = confusion_matrix(fold[\"y_test\"], label_pred)\n",
    "                if(conf[0][0]+conf[1][0]):\n",
    "                    sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "                else:\n",
    "                    sens = 0.0\n",
    "                if(conf[1][1]+conf[0][1]):\n",
    "                    spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "                else:\n",
    "                    spec = 0.0\n",
    "                if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "                    mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "                else:\n",
    "                    mcc= 0.0\n",
    "                fpr, tpr, thresholds = roc_curve(fold[\"y_test\"], y_pred)\n",
    "                auc = roc_auc_score(fold[\"y_test\"], y_pred)\n",
    "\n",
    "                evaluations[\"Model\"].append(current_dataset_variety)\n",
    "                evaluations[\"Kernel_Length\"].append(kernel_length)\n",
    "                evaluations[\"Dataset\"].append(current_dataset_variety)\n",
    "                evaluations[\"Fold\"].append(i)\n",
    "                evaluations[\"Train_Test\"].append(\"Test\")\n",
    "                evaluations[\"Accuracy\"].append(acc)\n",
    "                evaluations[\"Precision\"].append(prec)\n",
    "                evaluations[\"TPR\"].append(tpr)\n",
    "                evaluations[\"FPR\"].append(fpr)\n",
    "                evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "                evaluations[\"AUC\"].append(auc)\n",
    "                evaluations[\"Sensitivity\"].append(sens)\n",
    "                evaluations[\"Specificity\"].append(spec)\n",
    "                evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "                i = i+1\n",
    "                del model\n",
    "                tf.keras.backend.clear_session()\n",
    "\n",
    "            ##################################################################################\n",
    "            ##### Dump evaluations to a file\n",
    "            ##################################################################################\n",
    "\n",
    "            evalPath = os.path.join(outPath, expName, \"_Evaluation_All_Datasets\")\n",
    "            if(not os.path.isdir(evalPath)):\n",
    "                os.makedirs(evalPath)\n",
    "\n",
    "            pickle.dump(evaluations,\n",
    "                        open(os.path.join(evalPath, \"{}fold_evaluations.pickle\".format(n_fold)), \"wb\"))\n",
    "            \n",
    "    return evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = execute_model_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "File: Data\\Aziz\\HS_990.csv\n",
      "Positive: 495\n",
      "Negative: 495\n",
      "\n",
      "Train/Test model HS_990 on Fold #0.\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.6867 - val_loss: 0.7582\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6753 - val_loss: 0.7989\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6720 - val_loss: 0.8143\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6701 - val_loss: 0.8288\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6685 - val_loss: 0.8424\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6672 - val_loss: 0.8549\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6661 - val_loss: 0.8659\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6652 - val_loss: 0.8767\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6646 - val_loss: 0.8877\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6639 - val_loss: 0.8963\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6634 - val_loss: 0.9031\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6631 - val_loss: 0.9128\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6627 - val_loss: 0.9195\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6624 - val_loss: 0.9237\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6622 - val_loss: 0.9315\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6618 - val_loss: 0.9343\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6607 - val_loss: 0.8914\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6615 - val_loss: 0.9479\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6599 - val_loss: 0.8932\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6590 - val_loss: 0.9483\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6545 - val_loss: 0.9027\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6502 - val_loss: 0.9416\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6421 - val_loss: 0.9201\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6260 - val_loss: 0.8838\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6085 - val_loss: 0.9535\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5925 - val_loss: 0.9112\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5744 - val_loss: 0.8518\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5662 - val_loss: 0.8455\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5510 - val_loss: 0.9547\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5368 - val_loss: 0.8939\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5240 - val_loss: 0.9773\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5231 - val_loss: 0.9808\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5050 - val_loss: 0.8408\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4944 - val_loss: 0.9031\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4835 - val_loss: 0.9052\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4736 - val_loss: 0.9897\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4673 - val_loss: 1.0100\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4577 - val_loss: 0.9303\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4464 - val_loss: 0.9038\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4393 - val_loss: 1.0446\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4340 - val_loss: 0.9351\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4257 - val_loss: 0.9975\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4191 - val_loss: 1.0524\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4134 - val_loss: 0.9733\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4082 - val_loss: 0.9954\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4018 - val_loss: 1.0190\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3998 - val_loss: 1.0475\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3933 - val_loss: 0.9796\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3875 - val_loss: 1.0584\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3810 - val_loss: 0.8967\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3775 - val_loss: 1.1489\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3720 - val_loss: 0.9573\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3634 - val_loss: 1.0172\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3590 - val_loss: 0.9769\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3523 - val_loss: 1.0956\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3482 - val_loss: 1.0839\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3427 - val_loss: 1.0230\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3359 - val_loss: 0.8669\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3437 - val_loss: 0.8535\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3543 - val_loss: 1.1789\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3251 - val_loss: 1.0924\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3168 - val_loss: 1.0937\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3134 - val_loss: 1.0851\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3103 - val_loss: 1.1052\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3075 - val_loss: 1.1088\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3048 - val_loss: 1.1116\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3023 - val_loss: 1.1122\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2999 - val_loss: 1.1152\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2975 - val_loss: 1.1363\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2952 - val_loss: 1.1422\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2930 - val_loss: 1.1460\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2908 - val_loss: 1.1484\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2888 - val_loss: 1.1653\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2868 - val_loss: 1.1660\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2848 - val_loss: 1.1361\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2826 - val_loss: 1.0625\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2790 - val_loss: 1.1573\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2769 - val_loss: 1.1902\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2750 - val_loss: 1.1775\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.2733 - val_loss: 1.1716\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2716 - val_loss: 1.1955\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2700 - val_loss: 1.1893\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2684 - val_loss: 1.1985\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2668 - val_loss: 1.1949\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2654 - val_loss: 1.2161\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2639 - val_loss: 1.2000\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2625 - val_loss: 1.2099\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2611 - val_loss: 1.2166\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2598 - val_loss: 1.2242\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2585 - val_loss: 1.2297\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2572 - val_loss: 1.2267\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2560 - val_loss: 1.2269\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2548 - val_loss: 1.2386\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2536 - val_loss: 1.2359\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2524 - val_loss: 1.2467\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2513 - val_loss: 1.2534\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2502 - val_loss: 1.2474\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2492 - val_loss: 1.2499\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2481 - val_loss: 1.2595\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2471 - val_loss: 1.2649\n",
      "\n",
      "Train/Test model HS_990 on Fold #1.\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6870 - val_loss: 0.7673\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6741 - val_loss: 0.8042\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6708 - val_loss: 0.8277\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6686 - val_loss: 0.8449\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6669 - val_loss: 0.8591\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6657 - val_loss: 0.8730\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6648 - val_loss: 0.8852\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6640 - val_loss: 0.8950\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6634 - val_loss: 0.9043\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6629 - val_loss: 0.9126\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6625 - val_loss: 0.9192\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6622 - val_loss: 0.9268\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6620 - val_loss: 0.9159\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6601 - val_loss: 0.8958\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6575 - val_loss: 0.9291\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6530 - val_loss: 0.9028\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6444 - val_loss: 0.9516\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6393 - val_loss: 0.9045\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6261 - val_loss: 0.9119\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6180 - val_loss: 1.0024\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6085 - val_loss: 0.9082\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5983 - val_loss: 0.8078\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5974 - val_loss: 0.8078\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5681 - val_loss: 0.9092\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5513 - val_loss: 1.0123\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5620 - val_loss: 0.7992\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5370 - val_loss: 0.8900\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5159 - val_loss: 0.8822\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5012 - val_loss: 0.9164\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4893 - val_loss: 0.8577\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4830 - val_loss: 0.9233\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4692 - val_loss: 0.8402\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4600 - val_loss: 0.9961\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4517 - val_loss: 0.8925\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4475 - val_loss: 0.9665\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4345 - val_loss: 0.9357\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4275 - val_loss: 0.9629\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4205 - val_loss: 0.9461\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4142 - val_loss: 0.8920\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4083 - val_loss: 0.9389\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4019 - val_loss: 0.9403\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3973 - val_loss: 1.0180\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3929 - val_loss: 1.0109\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3875 - val_loss: 0.9797\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3821 - val_loss: 1.0055\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3782 - val_loss: 0.9788\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3743 - val_loss: 1.0934\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3696 - val_loss: 1.0629\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3648 - val_loss: 1.0375\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3604 - val_loss: 0.9381\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3578 - val_loss: 1.0515\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3536 - val_loss: 1.0618\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3503 - val_loss: 1.0627\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3475 - val_loss: 1.0706\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3444 - val_loss: 1.1885\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3423 - val_loss: 1.1591\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3405 - val_loss: 1.1341\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3353 - val_loss: 1.1868\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3327 - val_loss: 1.1017\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3243 - val_loss: 1.0499\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3213 - val_loss: 1.1182\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3186 - val_loss: 1.1199\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3163 - val_loss: 1.1334\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3140 - val_loss: 1.1733\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3119 - val_loss: 1.1736\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3098 - val_loss: 1.2582\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3063 - val_loss: 1.1826\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3042 - val_loss: 1.1665\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3024 - val_loss: 1.1855\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3005 - val_loss: 1.2055\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2988 - val_loss: 1.1716\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2971 - val_loss: 1.2049\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2955 - val_loss: 1.2097\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2939 - val_loss: 1.1890\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2923 - val_loss: 1.2131\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2908 - val_loss: 1.2014\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2893 - val_loss: 1.2641\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2882 - val_loss: 1.1501\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2850 - val_loss: 1.1725\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2832 - val_loss: 1.2309\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2817 - val_loss: 1.2251\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2803 - val_loss: 1.2533\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2790 - val_loss: 1.2347\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2778 - val_loss: 1.2632\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2766 - val_loss: 1.2516\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2754 - val_loss: 1.2623\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2743 - val_loss: 1.2519\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2731 - val_loss: 1.3259\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3085 - val_loss: 1.2402\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2793 - val_loss: 1.3747\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2759 - val_loss: 1.2740\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2849 - val_loss: 1.5983\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2766 - val_loss: 1.2383\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2657 - val_loss: 1.2895\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2643 - val_loss: 1.3255\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2631 - val_loss: 1.3220\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2621 - val_loss: 1.3704\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2610 - val_loss: 1.1694\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2579 - val_loss: 1.3746\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2568 - val_loss: 1.2874\n",
      "\n",
      "Train/Test model HS_990 on Fold #2.\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.6868 - val_loss: 0.7616\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6744 - val_loss: 0.8004\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6716 - val_loss: 0.8188\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6695 - val_loss: 0.8347\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6679 - val_loss: 0.8482\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6667 - val_loss: 0.8600\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6658 - val_loss: 0.8718\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6649 - val_loss: 0.8808\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6643 - val_loss: 0.8915\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6637 - val_loss: 0.8974\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6632 - val_loss: 0.9014\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6664 - val_loss: 0.9066\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6617 - val_loss: 0.8910\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6596 - val_loss: 0.8832\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6544 - val_loss: 0.8955\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6466 - val_loss: 0.8273\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6345 - val_loss: 0.8402\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6185 - val_loss: 0.8772\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6059 - val_loss: 0.8858\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5954 - val_loss: 0.7939\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5809 - val_loss: 0.9110\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5694 - val_loss: 0.8751\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5480 - val_loss: 0.8255\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5349 - val_loss: 0.8963\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5208 - val_loss: 0.9310\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5097 - val_loss: 0.9307\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4906 - val_loss: 0.8553\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4822 - val_loss: 0.9007\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4714 - val_loss: 0.9902\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4691 - val_loss: 0.9224\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4518 - val_loss: 0.9698\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4430 - val_loss: 0.9093\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4367 - val_loss: 1.0122\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4293 - val_loss: 0.9824\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4221 - val_loss: 0.9799\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4156 - val_loss: 1.0032\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4104 - val_loss: 1.0206\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4058 - val_loss: 1.0268\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4016 - val_loss: 1.0366\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3980 - val_loss: 1.0724\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3933 - val_loss: 1.0162\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3896 - val_loss: 1.0444\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3863 - val_loss: 1.0131\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3811 - val_loss: 1.0657\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3768 - val_loss: 1.0889\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3725 - val_loss: 1.0964\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3692 - val_loss: 1.0866\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3665 - val_loss: 1.0534\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3610 - val_loss: 1.0728\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3580 - val_loss: 1.1061\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3553 - val_loss: 1.0853\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3526 - val_loss: 1.1278\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3502 - val_loss: 1.1272\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3467 - val_loss: 1.0124\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3455 - val_loss: 1.1511\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3417 - val_loss: 1.1349\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3390 - val_loss: 1.1269\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3368 - val_loss: 1.1470\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3347 - val_loss: 1.1569\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3327 - val_loss: 1.1541\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3308 - val_loss: 1.1627\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3289 - val_loss: 1.1661\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3271 - val_loss: 1.1654\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3253 - val_loss: 1.1753\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3234 - val_loss: 1.1750\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3212 - val_loss: 1.1566\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3172 - val_loss: 1.1890\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3150 - val_loss: 1.2075\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3111 - val_loss: 1.2283\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3090 - val_loss: 1.2327\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3074 - val_loss: 1.2311\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3059 - val_loss: 1.2138\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3044 - val_loss: 1.2499\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3030 - val_loss: 1.2406\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3016 - val_loss: 1.2461\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3003 - val_loss: 1.2515\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2990 - val_loss: 1.2756\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2977 - val_loss: 1.2964\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3056 - val_loss: 1.3905\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3078 - val_loss: 1.4027\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3095 - val_loss: 1.2166\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2976 - val_loss: 1.2978\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2987 - val_loss: 1.1852\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2943 - val_loss: 1.1391\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2897 - val_loss: 1.1343\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2873 - val_loss: 1.3256\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2854 - val_loss: 1.2544\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2843 - val_loss: 1.2833\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2833 - val_loss: 1.2774\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2824 - val_loss: 1.2884\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2814 - val_loss: 1.2911\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2805 - val_loss: 1.3002\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2796 - val_loss: 1.2984\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2788 - val_loss: 1.3082\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2779 - val_loss: 1.3090\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2771 - val_loss: 1.3092\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2763 - val_loss: 1.3154\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2756 - val_loss: 1.3196\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2748 - val_loss: 1.3219\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2740 - val_loss: 1.3236\n",
      "\n",
      "Train/Test model HS_990 on Fold #3.\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.6865 - val_loss: 0.7634\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6758 - val_loss: 0.7987\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6716 - val_loss: 0.8211\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6692 - val_loss: 0.8389\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6675 - val_loss: 0.8548\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6662 - val_loss: 0.8681\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6653 - val_loss: 0.8797\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6644 - val_loss: 0.8881\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6638 - val_loss: 0.8972\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6633 - val_loss: 0.9049\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6630 - val_loss: 0.9127\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6626 - val_loss: 0.9191\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6624 - val_loss: 0.9259\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6621 - val_loss: 0.9185\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6622 - val_loss: 0.9376\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6620 - val_loss: 0.9433\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6617 - val_loss: 0.9439\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6617 - val_loss: 0.9475\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6616 - val_loss: 0.9489\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6617 - val_loss: 0.9563\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6614 - val_loss: 0.9577\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6612 - val_loss: 0.9557\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6633 - val_loss: 0.9593\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6595 - val_loss: 0.9061\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6520 - val_loss: 0.8602\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6435 - val_loss: 0.8544\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6343 - val_loss: 0.9659\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6218 - val_loss: 0.9488\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6078 - val_loss: 0.8572\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5904 - val_loss: 0.8567\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5734 - val_loss: 0.8684\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5569 - val_loss: 0.8414\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5380 - val_loss: 0.8382\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5216 - val_loss: 0.9131\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5014 - val_loss: 0.8717\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4905 - val_loss: 0.9670\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4725 - val_loss: 0.9203\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4603 - val_loss: 0.9206\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4475 - val_loss: 0.9601\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4368 - val_loss: 0.9062\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4300 - val_loss: 0.9814\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4205 - val_loss: 0.9392\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4131 - val_loss: 0.9671\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4069 - val_loss: 1.0329\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4003 - val_loss: 0.9808\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3948 - val_loss: 0.9993\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3900 - val_loss: 1.0149\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3855 - val_loss: 1.0430\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3814 - val_loss: 1.0621\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3765 - val_loss: 1.0231\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3710 - val_loss: 1.0582\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3671 - val_loss: 1.0695\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3622 - val_loss: 1.0591\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3585 - val_loss: 1.0511\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3552 - val_loss: 1.0852\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3520 - val_loss: 1.0967\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3490 - val_loss: 1.0982\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3462 - val_loss: 1.1165\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3434 - val_loss: 1.1194\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3408 - val_loss: 1.1258\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3383 - val_loss: 1.1426\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3358 - val_loss: 1.1134\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3335 - val_loss: 1.2067\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3297 - val_loss: 1.1631\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3271 - val_loss: 1.1571\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3248 - val_loss: 1.1616\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3227 - val_loss: 1.1485\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3207 - val_loss: 1.1554\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3187 - val_loss: 1.1475\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3171 - val_loss: 1.1920\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3129 - val_loss: 1.1675\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3094 - val_loss: 1.1653\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3070 - val_loss: 1.1690\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3050 - val_loss: 1.1654\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3033 - val_loss: 1.1602\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3014 - val_loss: 1.0530\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2986 - val_loss: 1.1164\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2962 - val_loss: 1.2071\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2945 - val_loss: 1.1948\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3092 - val_loss: 0.7966\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3333 - val_loss: 1.1786\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2920 - val_loss: 1.2000\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2883 - val_loss: 1.2956\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2858 - val_loss: 1.2435\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2842 - val_loss: 1.2785\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2828 - val_loss: 1.2619\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2815 - val_loss: 1.2902\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2802 - val_loss: 1.2796\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2790 - val_loss: 1.2908\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2779 - val_loss: 1.2984\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2767 - val_loss: 1.3106\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2756 - val_loss: 1.3153\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2745 - val_loss: 1.3205\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2733 - val_loss: 1.3805\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2702 - val_loss: 1.2501\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2690 - val_loss: 1.3385\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2680 - val_loss: 1.3254\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2670 - val_loss: 1.3227\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2661 - val_loss: 1.3375\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2651 - val_loss: 1.3383\n",
      "\n",
      "Train/Test model HS_990 on Fold #4.\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.6865 - val_loss: 0.7647\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6744 - val_loss: 0.8062\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6708 - val_loss: 0.8231\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6691 - val_loss: 0.8413\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6673 - val_loss: 0.8524\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6664 - val_loss: 0.8668\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6652 - val_loss: 0.8753\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6646 - val_loss: 0.8877\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6638 - val_loss: 0.8959\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6634 - val_loss: 0.9044\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6631 - val_loss: 0.9167\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6626 - val_loss: 0.9203\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6623 - val_loss: 0.9259\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6622 - val_loss: 0.9328\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6619 - val_loss: 0.9331\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6613 - val_loss: 0.9360\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6593 - val_loss: 0.9265\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6553 - val_loss: 0.9438\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6506 - val_loss: 0.9420\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6432 - val_loss: 0.9358\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6349 - val_loss: 0.8787\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6214 - val_loss: 0.9899\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6201 - val_loss: 0.8778\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5990 - val_loss: 0.9267\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5895 - val_loss: 0.9009\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5793 - val_loss: 0.8529\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5699 - val_loss: 0.9581\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5529 - val_loss: 0.9148\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5395 - val_loss: 0.9579\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5256 - val_loss: 0.9544\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5162 - val_loss: 0.9754\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5086 - val_loss: 0.9455\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5014 - val_loss: 0.9784\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4913 - val_loss: 0.9426\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4833 - val_loss: 0.9854\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4754 - val_loss: 0.9990\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4697 - val_loss: 0.9923\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4641 - val_loss: 1.0123\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4580 - val_loss: 1.0503\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4533 - val_loss: 0.9772\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4473 - val_loss: 1.0135\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4428 - val_loss: 1.0206\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4394 - val_loss: 1.0090\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4348 - val_loss: 1.0688\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4302 - val_loss: 1.0169\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4259 - val_loss: 1.0233\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4222 - val_loss: 1.0459\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.4192 - val_loss: 1.0536\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4143 - val_loss: 1.0613\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4110 - val_loss: 1.0638\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4079 - val_loss: 1.0421\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4053 - val_loss: 1.0726\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4009 - val_loss: 1.0623\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3980 - val_loss: 1.0620\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3951 - val_loss: 1.0728\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3913 - val_loss: 1.0043\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3926 - val_loss: 1.0586\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3870 - val_loss: 1.1215\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3829 - val_loss: 1.0900\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3799 - val_loss: 1.1061\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3772 - val_loss: 1.1187\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3749 - val_loss: 1.1135\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3728 - val_loss: 1.1151\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3707 - val_loss: 1.1094\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3688 - val_loss: 1.1242\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3669 - val_loss: 1.1214\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3650 - val_loss: 1.1304\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3632 - val_loss: 1.1236\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3615 - val_loss: 1.1428\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3598 - val_loss: 1.1324\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3581 - val_loss: 1.1349\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3566 - val_loss: 1.1803\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3532 - val_loss: 1.1239\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3514 - val_loss: 1.1199\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3498 - val_loss: 1.1741\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3483 - val_loss: 1.1564\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3469 - val_loss: 1.1664\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3455 - val_loss: 1.1623\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3442 - val_loss: 1.1623\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3429 - val_loss: 1.1686\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3416 - val_loss: 1.1728\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3404 - val_loss: 1.1863\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3391 - val_loss: 1.1809\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3380 - val_loss: 1.1882\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3369 - val_loss: 1.1913\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3358 - val_loss: 1.1946\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3347 - val_loss: 1.1966\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3336 - val_loss: 1.1933\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3326 - val_loss: 1.2067\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3316 - val_loss: 1.1991\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3307 - val_loss: 1.2093\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3297 - val_loss: 1.2078\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3288 - val_loss: 1.2145\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3279 - val_loss: 1.2149\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3270 - val_loss: 1.2163\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3262 - val_loss: 1.2184\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3253 - val_loss: 1.2138\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3246 - val_loss: 1.2652\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3469 - val_loss: 1.1810\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3304 - val_loss: 1.0893\n",
      "\n",
      "======================================================================\n",
      "\n",
      "File: Data\\Aziz\\MM_944.csv\n",
      "Positive: 472\n",
      "Negative: 472\n",
      "\n",
      "Train/Test model MM_944 on Fold #0.\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 0.6884 - val_loss: 0.7503\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6764 - val_loss: 0.8001\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6719 - val_loss: 0.8169\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6701 - val_loss: 0.8308\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6688 - val_loss: 0.8462\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6675 - val_loss: 0.8575\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6665 - val_loss: 0.8669\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6657 - val_loss: 0.8748\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6651 - val_loss: 0.8846\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6646 - val_loss: 0.8944\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6641 - val_loss: 0.9010\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6638 - val_loss: 0.9103\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6634 - val_loss: 0.9172\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6633 - val_loss: 0.9241\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6629 - val_loss: 0.9250\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6628 - val_loss: 0.9290\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6632 - val_loss: 0.9005\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6590 - val_loss: 0.8963\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6530 - val_loss: 0.8739\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6453 - val_loss: 0.9405\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6379 - val_loss: 0.8570\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6245 - val_loss: 0.8366\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6164 - val_loss: 0.8824\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6016 - val_loss: 0.8366\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5890 - val_loss: 0.7963\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5826 - val_loss: 0.8794\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5701 - val_loss: 0.8422\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5574 - val_loss: 0.8377\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5513 - val_loss: 0.8750\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5441 - val_loss: 0.8631\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5329 - val_loss: 0.8372\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5256 - val_loss: 0.8575\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5115 - val_loss: 0.8580\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5028 - val_loss: 0.8677\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4926 - val_loss: 0.8739\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4860 - val_loss: 0.8361\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4787 - val_loss: 0.8475\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4712 - val_loss: 0.8756\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4656 - val_loss: 0.8836\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4595 - val_loss: 0.8657\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4539 - val_loss: 0.8733\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4489 - val_loss: 0.8581\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4441 - val_loss: 0.8566\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4390 - val_loss: 0.8717\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4334 - val_loss: 0.8725\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4289 - val_loss: 0.8629\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4250 - val_loss: 0.8631\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4210 - val_loss: 0.8740\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4173 - val_loss: 0.8777\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4138 - val_loss: 0.8782\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4103 - val_loss: 0.8824\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4070 - val_loss: 0.8632\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4027 - val_loss: 0.8796\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3992 - val_loss: 0.8801\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3960 - val_loss: 0.8832\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3930 - val_loss: 0.8821\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3902 - val_loss: 0.8940\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3874 - val_loss: 0.8987\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3846 - val_loss: 0.8974\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3820 - val_loss: 0.9003\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3794 - val_loss: 0.8530\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3755 - val_loss: 0.8934\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3728 - val_loss: 0.9179\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3704 - val_loss: 0.8965\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3681 - val_loss: 0.8983\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3658 - val_loss: 0.9085\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3637 - val_loss: 0.9073\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3616 - val_loss: 0.9072\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3595 - val_loss: 0.9160\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3584 - val_loss: 0.8921\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3566 - val_loss: 0.9623\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.3535 - val_loss: 0.9154\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3502 - val_loss: 0.9236\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3480 - val_loss: 0.9435\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3462 - val_loss: 0.9335\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3444 - val_loss: 0.9192\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3427 - val_loss: 0.9447\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3411 - val_loss: 0.9295\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3394 - val_loss: 0.9361\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3379 - val_loss: 0.9406\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3364 - val_loss: 0.9357\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3349 - val_loss: 0.9385\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3335 - val_loss: 0.9358\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3320 - val_loss: 0.9201\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3314 - val_loss: 1.0376\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3481 - val_loss: 1.0730\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3527 - val_loss: 0.5967\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3609 - val_loss: 0.9597\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3354 - val_loss: 0.9971\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3203 - val_loss: 1.0173\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3150 - val_loss: 0.9563\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3134 - val_loss: 1.0043\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3115 - val_loss: 0.9573\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3100 - val_loss: 0.9931\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.3088 - val_loss: 0.9863\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3076 - val_loss: 0.9796\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3064 - val_loss: 0.9859\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3053 - val_loss: 0.9867\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3042 - val_loss: 0.9888\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3032 - val_loss: 0.9922\n",
      "\n",
      "Train/Test model MM_944 on Fold #1.\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6876 - val_loss: 0.7554\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6754 - val_loss: 0.8025\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6712 - val_loss: 0.8231\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6692 - val_loss: 0.8406\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6677 - val_loss: 0.8554\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6666 - val_loss: 0.8676\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6657 - val_loss: 0.8785\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6651 - val_loss: 0.8886\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6645 - val_loss: 0.8967\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6640 - val_loss: 0.9029\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6636 - val_loss: 0.9097\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6637 - val_loss: 0.9165\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6630 - val_loss: 0.9228\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6628 - val_loss: 0.9290\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6625 - val_loss: 0.9333\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6618 - val_loss: 0.8863\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6551 - val_loss: 0.9016\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6476 - val_loss: 0.8730\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6342 - val_loss: 0.8902\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6193 - val_loss: 0.8519\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6057 - val_loss: 0.8101\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5908 - val_loss: 0.8345\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5797 - val_loss: 0.8318\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5653 - val_loss: 0.7542\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5535 - val_loss: 0.8957\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5351 - val_loss: 0.7757\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5233 - val_loss: 0.7713\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5080 - val_loss: 0.8304\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4935 - val_loss: 0.8044\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4834 - val_loss: 0.8442\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4744 - val_loss: 0.8084\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4657 - val_loss: 0.8685\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4590 - val_loss: 0.7718\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4504 - val_loss: 0.8848\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4422 - val_loss: 0.7906\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4351 - val_loss: 0.9304\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4333 - val_loss: 0.8310\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4213 - val_loss: 0.8655\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4140 - val_loss: 0.8626\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4090 - val_loss: 0.8672\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4045 - val_loss: 0.8730\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4002 - val_loss: 0.8721\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3962 - val_loss: 0.8724\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3924 - val_loss: 0.8562\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3886 - val_loss: 0.8866\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3838 - val_loss: 0.8870\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3804 - val_loss: 0.8943\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3770 - val_loss: 0.9062\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3740 - val_loss: 0.8873\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3709 - val_loss: 0.8937\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3680 - val_loss: 0.9039\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3653 - val_loss: 0.9079\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3625 - val_loss: 0.9024\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3599 - val_loss: 0.9263\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3573 - val_loss: 0.9161\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3550 - val_loss: 0.9185\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3526 - val_loss: 0.9321\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3504 - val_loss: 0.9229\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3481 - val_loss: 0.9330\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3460 - val_loss: 0.9382\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3439 - val_loss: 0.9391\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3419 - val_loss: 0.9303\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3398 - val_loss: 0.9411\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3378 - val_loss: 0.9380\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3359 - val_loss: 0.9402\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3342 - val_loss: 0.9503\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3324 - val_loss: 0.9506\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3307 - val_loss: 0.9597\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3291 - val_loss: 0.9566\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3276 - val_loss: 0.9576\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3260 - val_loss: 0.9616\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3245 - val_loss: 0.9736\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3231 - val_loss: 0.9663\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3217 - val_loss: 0.9726\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3203 - val_loss: 0.9765\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3190 - val_loss: 0.9825\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3177 - val_loss: 0.9749\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3164 - val_loss: 0.9818\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3152 - val_loss: 0.9897\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3140 - val_loss: 0.9879\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3129 - val_loss: 0.9878\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3117 - val_loss: 0.9871\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3106 - val_loss: 0.9970\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3095 - val_loss: 0.9989\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3085 - val_loss: 0.9940\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3075 - val_loss: 1.0011\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3065 - val_loss: 1.0046\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3056 - val_loss: 1.0040\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3046 - val_loss: 1.0108\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3037 - val_loss: 1.0072\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3028 - val_loss: 1.0068\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3019 - val_loss: 1.0076\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3012 - val_loss: 1.0268\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3003 - val_loss: 1.0166\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2995 - val_loss: 1.0169\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2987 - val_loss: 1.0268\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2980 - val_loss: 1.0192\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2972 - val_loss: 1.0253\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2965 - val_loss: 1.0298\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2958 - val_loss: 1.0270\n",
      "\n",
      "Train/Test model MM_944 on Fold #2.\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6870 - val_loss: 0.7593\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6752 - val_loss: 0.7981\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6717 - val_loss: 0.8167\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6697 - val_loss: 0.8337\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6679 - val_loss: 0.8468\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6667 - val_loss: 0.8600\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6656 - val_loss: 0.8707\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6648 - val_loss: 0.8801\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6643 - val_loss: 0.8886\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6640 - val_loss: 0.8998\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6631 - val_loss: 0.9058\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6622 - val_loss: 0.8699\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6593 - val_loss: 0.8931\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6542 - val_loss: 0.9255\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6525 - val_loss: 0.9307\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6510 - val_loss: 0.8111\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6400 - val_loss: 0.8536\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6289 - val_loss: 0.8834\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6116 - val_loss: 0.7891\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5967 - val_loss: 0.8370\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5763 - val_loss: 0.7737\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5624 - val_loss: 0.8478\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5442 - val_loss: 0.8111\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5283 - val_loss: 0.8650\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5159 - val_loss: 0.7693\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5042 - val_loss: 0.8103\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4927 - val_loss: 0.7943\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4824 - val_loss: 0.8407\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4731 - val_loss: 0.8276\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4639 - val_loss: 0.7936\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4566 - val_loss: 0.8769\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4482 - val_loss: 0.8287\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4415 - val_loss: 0.8453\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4358 - val_loss: 0.8733\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4307 - val_loss: 0.8877\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4258 - val_loss: 0.8262\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4211 - val_loss: 0.8733\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4164 - val_loss: 0.8266\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4114 - val_loss: 0.8802\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4088 - val_loss: 0.8327\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4018 - val_loss: 0.8398\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3973 - val_loss: 0.9078\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3916 - val_loss: 0.9237\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3869 - val_loss: 0.9041\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3836 - val_loss: 0.9185\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3803 - val_loss: 0.9241\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3772 - val_loss: 0.9051\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3730 - val_loss: 0.9358\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3698 - val_loss: 0.9081\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3650 - val_loss: 0.9117\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3626 - val_loss: 0.9906\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3593 - val_loss: 1.0089\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3560 - val_loss: 0.9030\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3512 - val_loss: 1.0225\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3472 - val_loss: 1.0676\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3464 - val_loss: 0.8084\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3429 - val_loss: 0.8900\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3397 - val_loss: 0.9244\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3374 - val_loss: 0.9515\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3351 - val_loss: 0.9882\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3330 - val_loss: 0.9592\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3310 - val_loss: 0.9801\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3291 - val_loss: 0.9850\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3271 - val_loss: 0.9761\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3253 - val_loss: 0.9824\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3236 - val_loss: 0.9838\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3219 - val_loss: 0.9961\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3201 - val_loss: 0.9939\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3186 - val_loss: 0.9924\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3169 - val_loss: 1.0030\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3154 - val_loss: 0.9922\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3139 - val_loss: 0.9967\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3125 - val_loss: 1.0413\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3196 - val_loss: 0.9940\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3507 - val_loss: 0.9746\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3235 - val_loss: 1.2711\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3148 - val_loss: 0.8621\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3063 - val_loss: 0.9027\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3011 - val_loss: 1.0143\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2985 - val_loss: 1.0175\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2971 - val_loss: 1.0283\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2958 - val_loss: 1.0216\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2946 - val_loss: 1.0334\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2934 - val_loss: 1.0349\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2923 - val_loss: 1.0346\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2912 - val_loss: 1.0565\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2901 - val_loss: 1.0395\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2890 - val_loss: 1.0464\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2880 - val_loss: 1.0504\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2870 - val_loss: 1.0538\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2860 - val_loss: 1.0572\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2851 - val_loss: 1.0558\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2841 - val_loss: 1.0576\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2832 - val_loss: 1.0652\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2823 - val_loss: 1.0638\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2815 - val_loss: 1.0696\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2806 - val_loss: 1.0658\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2798 - val_loss: 1.0815\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2790 - val_loss: 1.0750\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2782 - val_loss: 1.0830\n",
      "\n",
      "Train/Test model MM_944 on Fold #3.\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6879 - val_loss: 0.7540\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6758 - val_loss: 0.7964\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6718 - val_loss: 0.8176\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6696 - val_loss: 0.8343\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6679 - val_loss: 0.8461\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6669 - val_loss: 0.8612\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6656 - val_loss: 0.8700\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6649 - val_loss: 0.8812\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6642 - val_loss: 0.8889\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6637 - val_loss: 0.8990\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6631 - val_loss: 0.9045\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6621 - val_loss: 0.9108\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6623 - val_loss: 0.9255\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6617 - val_loss: 0.9291\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6609 - val_loss: 0.9246\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6549 - val_loss: 0.8669\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6452 - val_loss: 0.8777\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6294 - val_loss: 0.7963\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6148 - val_loss: 0.8669\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6038 - val_loss: 0.7674\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5897 - val_loss: 0.8929\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5756 - val_loss: 0.7921\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5539 - val_loss: 0.7758\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5390 - val_loss: 0.7172\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5232 - val_loss: 0.7799\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5055 - val_loss: 0.7948\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4948 - val_loss: 0.7760\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4853 - val_loss: 0.7675\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4725 - val_loss: 0.7966\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4629 - val_loss: 0.7901\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4551 - val_loss: 0.8169\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4480 - val_loss: 0.8075\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4405 - val_loss: 0.8461\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4343 - val_loss: 0.8739\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4275 - val_loss: 0.8242\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4204 - val_loss: 0.8511\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4151 - val_loss: 0.8346\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4077 - val_loss: 0.8677\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4018 - val_loss: 0.8912\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3966 - val_loss: 0.7938\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3916 - val_loss: 0.8360\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3857 - val_loss: 0.7737\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3893 - val_loss: 0.8631\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3768 - val_loss: 0.8518\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3685 - val_loss: 0.8283\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3632 - val_loss: 0.8443\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3602 - val_loss: 0.8186\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3537 - val_loss: 0.8445\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3491 - val_loss: 0.8230\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3442 - val_loss: 0.8383\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3406 - val_loss: 0.8863\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3375 - val_loss: 0.8699\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3344 - val_loss: 0.8849\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3316 - val_loss: 0.8761\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3288 - val_loss: 0.8822\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3261 - val_loss: 0.8996\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3228 - val_loss: 0.8148\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.3194 - val_loss: 0.8964\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3168 - val_loss: 0.9484\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3128 - val_loss: 1.0080\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3102 - val_loss: 0.8988\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3072 - val_loss: 0.8923\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3050 - val_loss: 0.9075\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3027 - val_loss: 0.9130\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3006 - val_loss: 0.8851\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2971 - val_loss: 0.8465\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2952 - val_loss: 0.8811\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2924 - val_loss: 0.8846\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2881 - val_loss: 0.9844\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2859 - val_loss: 0.9089\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2840 - val_loss: 0.9429\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2822 - val_loss: 0.9348\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2805 - val_loss: 0.9473\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2787 - val_loss: 0.9361\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2771 - val_loss: 0.9430\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2754 - val_loss: 0.9499\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2739 - val_loss: 0.9516\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2723 - val_loss: 0.9558\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2708 - val_loss: 0.9537\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2693 - val_loss: 0.9576\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2679 - val_loss: 0.9587\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2666 - val_loss: 0.9641\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2652 - val_loss: 0.9649\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2638 - val_loss: 0.9687\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2626 - val_loss: 0.9711\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2613 - val_loss: 0.9712\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2601 - val_loss: 0.9707\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2589 - val_loss: 0.9752\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2577 - val_loss: 0.9722\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2566 - val_loss: 0.9652\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2554 - val_loss: 0.9718\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2546 - val_loss: 1.0737\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2538 - val_loss: 0.8845\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2550 - val_loss: 1.0190\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2499 - val_loss: 1.0139\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2477 - val_loss: 0.9921\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2463 - val_loss: 1.0416\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2446 - val_loss: 1.0222\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2423 - val_loss: 1.0586\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2412 - val_loss: 0.9212\n",
      "\n",
      "Train/Test model MM_944 on Fold #4.\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6876 - val_loss: 0.7588\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6753 - val_loss: 0.7997\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6717 - val_loss: 0.8156\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6700 - val_loss: 0.8328\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6683 - val_loss: 0.8449\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6670 - val_loss: 0.8557\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6661 - val_loss: 0.8671\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6652 - val_loss: 0.8765\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6644 - val_loss: 0.8833\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6620 - val_loss: 0.8726\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6570 - val_loss: 0.8480\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6492 - val_loss: 0.8686\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6413 - val_loss: 0.8594\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6325 - val_loss: 0.8682\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6235 - val_loss: 0.8312\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6178 - val_loss: 0.8658\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6067 - val_loss: 0.8658\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5991 - val_loss: 0.8631\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5870 - val_loss: 0.8783\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5776 - val_loss: 0.8391\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5676 - val_loss: 0.7930\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5601 - val_loss: 0.8846\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5484 - val_loss: 0.8830\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5390 - val_loss: 0.8213\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5310 - val_loss: 0.8271\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5205 - val_loss: 0.8477\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5110 - val_loss: 0.8663\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5033 - val_loss: 0.8671\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4950 - val_loss: 0.8263\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4881 - val_loss: 0.8674\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4808 - val_loss: 0.8208\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4764 - val_loss: 0.8960\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4680 - val_loss: 0.8298\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4615 - val_loss: 0.8638\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4561 - val_loss: 0.8428\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4510 - val_loss: 0.8572\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4462 - val_loss: 0.8632\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4414 - val_loss: 0.8161\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4370 - val_loss: 0.8823\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4319 - val_loss: 0.9204\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4267 - val_loss: 0.8743\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4224 - val_loss: 0.8859\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4183 - val_loss: 0.8834\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4145 - val_loss: 0.8856\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4107 - val_loss: 0.8792\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4073 - val_loss: 0.8714\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4038 - val_loss: 0.8771\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4005 - val_loss: 0.8863\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3972 - val_loss: 0.8865\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3942 - val_loss: 0.8753\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3911 - val_loss: 0.8644\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3882 - val_loss: 0.8765\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3853 - val_loss: 0.9171\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3825 - val_loss: 0.8777\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3797 - val_loss: 0.9064\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3769 - val_loss: 0.8575\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3748 - val_loss: 1.0134\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3719 - val_loss: 0.8365\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3675 - val_loss: 0.8724\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3646 - val_loss: 0.9650\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3611 - val_loss: 0.8964\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3580 - val_loss: 0.9115\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3535 - val_loss: 0.8606\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3492 - val_loss: 0.8699\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3468 - val_loss: 0.8999\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3444 - val_loss: 0.9642\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3422 - val_loss: 0.9200\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3400 - val_loss: 0.9042\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3379 - val_loss: 0.9194\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3358 - val_loss: 0.9229\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3339 - val_loss: 0.9231\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3319 - val_loss: 0.9345\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3300 - val_loss: 0.9198\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3282 - val_loss: 0.9209\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3264 - val_loss: 0.9343\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3246 - val_loss: 0.9255\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3229 - val_loss: 0.9331\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3212 - val_loss: 0.9408\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3196 - val_loss: 0.9288\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3180 - val_loss: 0.9333\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3165 - val_loss: 0.9418\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3149 - val_loss: 0.9403\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3134 - val_loss: 0.9430\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3120 - val_loss: 0.9413\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3105 - val_loss: 0.9440\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3092 - val_loss: 0.9436\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3078 - val_loss: 0.9430\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3064 - val_loss: 0.9505\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3052 - val_loss: 0.9454\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3039 - val_loss: 0.9543\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.3026 - val_loss: 0.9496\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3014 - val_loss: 0.9547\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3002 - val_loss: 0.9546\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2991 - val_loss: 0.9553\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2979 - val_loss: 0.9575\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2968 - val_loss: 0.9574\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2957 - val_loss: 0.9556\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2947 - val_loss: 0.9618\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2936 - val_loss: 0.9698\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.2927 - val_loss: 0.9657\n",
      "\n",
      "======================================================================\n",
      "\n",
      "File: Data\\Aziz\\SN_628.csv\n",
      "Positive: 314\n",
      "Negative: 314\n",
      "\n",
      "Train/Test model SN_628 on Fold #0.\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 0.6887 - val_loss: 0.7450\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6774 - val_loss: 0.7847\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6738 - val_loss: 0.7981\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6723 - val_loss: 0.8115\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6706 - val_loss: 0.8209\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6693 - val_loss: 0.8347\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6681 - val_loss: 0.8476\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6667 - val_loss: 0.8572\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6659 - val_loss: 0.8675\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6652 - val_loss: 0.8745\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6643 - val_loss: 0.8630\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6630 - val_loss: 0.8445\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6610 - val_loss: 0.8466\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6559 - val_loss: 0.8876\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6518 - val_loss: 0.9050\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6492 - val_loss: 0.9089\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6427 - val_loss: 0.9136\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6317 - val_loss: 0.8545\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6276 - val_loss: 0.8510\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6144 - val_loss: 0.8709\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6000 - val_loss: 0.9207\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5928 - val_loss: 0.8646\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5807 - val_loss: 0.8490\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5652 - val_loss: 0.9164\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5547 - val_loss: 0.9384\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5454 - val_loss: 0.8964\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5316 - val_loss: 0.9150\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5228 - val_loss: 0.9178\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5138 - val_loss: 0.9108\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5085 - val_loss: 0.8616\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5007 - val_loss: 0.8889\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4904 - val_loss: 0.8840\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4845 - val_loss: 0.9329\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4778 - val_loss: 0.9608\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4714 - val_loss: 0.9357\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4634 - val_loss: 0.9595\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4580 - val_loss: 0.9418\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4529 - val_loss: 0.9235\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4462 - val_loss: 0.9500\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4407 - val_loss: 0.9833\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4361 - val_loss: 0.9534\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4315 - val_loss: 0.9670\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4272 - val_loss: 0.9804\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4230 - val_loss: 0.9801\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4188 - val_loss: 0.9760\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4150 - val_loss: 0.9950\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4110 - val_loss: 0.9891\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4073 - val_loss: 0.9989\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4036 - val_loss: 1.0136\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3996 - val_loss: 1.0593\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3954 - val_loss: 0.9669\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3915 - val_loss: 1.0224\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3880 - val_loss: 1.0157\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3842 - val_loss: 1.1286\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3805 - val_loss: 1.0663\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3767 - val_loss: 0.9836\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3734 - val_loss: 1.0483\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3701 - val_loss: 0.9567\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3650 - val_loss: 1.0062\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3617 - val_loss: 1.0885\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3587 - val_loss: 1.0128\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3557 - val_loss: 1.0717\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3528 - val_loss: 1.0409\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3499 - val_loss: 1.0627\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3472 - val_loss: 1.0515\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3444 - val_loss: 1.0614\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3418 - val_loss: 1.0650\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3391 - val_loss: 1.0624\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3365 - val_loss: 1.0685\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3340 - val_loss: 1.0649\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3315 - val_loss: 1.0669\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3290 - val_loss: 1.0742\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3267 - val_loss: 1.0716\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3242 - val_loss: 1.0777\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3219 - val_loss: 1.0707\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3196 - val_loss: 1.0650\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3173 - val_loss: 1.0353\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3153 - val_loss: 1.0828\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3104 - val_loss: 1.1065\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3079 - val_loss: 1.0623\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3056 - val_loss: 1.0343\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3034 - val_loss: 1.0559\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3012 - val_loss: 1.0610\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2991 - val_loss: 1.0714\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2971 - val_loss: 1.0674\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2950 - val_loss: 1.0814\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2930 - val_loss: 1.0749\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2910 - val_loss: 1.0864\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2891 - val_loss: 1.0816\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2872 - val_loss: 1.0897\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2853 - val_loss: 1.0978\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2835 - val_loss: 1.0942\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2817 - val_loss: 1.1029\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2799 - val_loss: 1.1018\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2781 - val_loss: 1.1081\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2764 - val_loss: 1.1141\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2746 - val_loss: 1.1089\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2729 - val_loss: 1.1102\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2713 - val_loss: 1.1188\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2696 - val_loss: 1.1074\n",
      "\n",
      "Train/Test model SN_628 on Fold #1.\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.6877 - val_loss: 0.7459\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6769 - val_loss: 0.7897\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6729 - val_loss: 0.8058\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.6712 - val_loss: 0.8183\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6698 - val_loss: 0.8308\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6686 - val_loss: 0.8406\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6675 - val_loss: 0.8484\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6667 - val_loss: 0.8566\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6662 - val_loss: 0.8651\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6655 - val_loss: 0.8719\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6651 - val_loss: 0.8785\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6644 - val_loss: 0.8833\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6640 - val_loss: 0.8895\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6637 - val_loss: 0.8960\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6634 - val_loss: 0.9012\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6631 - val_loss: 0.9056\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6629 - val_loss: 0.9100\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.6627 - val_loss: 0.9150\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6625 - val_loss: 0.9194\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6623 - val_loss: 0.9229\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6622 - val_loss: 0.9268\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6621 - val_loss: 0.9310\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6619 - val_loss: 0.9345\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6618 - val_loss: 0.9375\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6618 - val_loss: 0.9391\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6617 - val_loss: 0.9426\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.6616 - val_loss: 0.9447\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6615 - val_loss: 0.9466\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.6615 - val_loss: 0.9489\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.6614 - val_loss: 0.9523\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6614 - val_loss: 0.9541\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.6614 - val_loss: 0.9576\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.6613 - val_loss: 0.9588\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6613 - val_loss: 0.9589\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6613 - val_loss: 0.9618\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6612 - val_loss: 0.9614\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6613 - val_loss: 0.9637\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6612 - val_loss: 0.9631\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6612 - val_loss: 0.9646\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6612 - val_loss: 0.9678\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6612 - val_loss: 0.9691\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6612 - val_loss: 0.9716\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6611 - val_loss: 0.9723\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6612 - val_loss: 0.9704\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6612 - val_loss: 0.9724\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9743\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6611 - val_loss: 0.9749\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6611 - val_loss: 0.9762\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9751\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6611 - val_loss: 0.9757\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6611 - val_loss: 0.9767\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6611 - val_loss: 0.9765\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6612 - val_loss: 0.9781\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9769\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9778\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9771\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9778\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9798\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9802\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9803\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9800\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9805\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9799\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9817\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9821\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9806\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9819\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.6611 - val_loss: 0.9829\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.6610 - val_loss: 0.9811\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6623 - val_loss: 0.9860\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9859\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6611 - val_loss: 0.9857\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6611 - val_loss: 0.9847\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6611 - val_loss: 0.9852\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6611 - val_loss: 0.9859\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6611 - val_loss: 0.9868\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9870\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6611 - val_loss: 0.9858\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6612 - val_loss: 0.9874\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6611 - val_loss: 0.9871\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6611 - val_loss: 0.9879\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6611 - val_loss: 0.9870\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9839\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9853\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9848\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9836\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9838\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.6611 - val_loss: 0.9840\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9846\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6611 - val_loss: 0.9834\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6611 - val_loss: 0.9839\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9835\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9845\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6611 - val_loss: 0.9863\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6611 - val_loss: 0.9880\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9853\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6606 - val_loss: 0.9813\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6597 - val_loss: 0.9846\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6530 - val_loss: 0.9277\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.6460 - val_loss: 0.9077\n",
      "\n",
      "Train/Test model SN_628 on Fold #2.\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.6886 - val_loss: 0.7420\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6777 - val_loss: 0.7946\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6728 - val_loss: 0.8043\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6714 - val_loss: 0.8147\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6703 - val_loss: 0.8249\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6691 - val_loss: 0.8336\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6681 - val_loss: 0.8419\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6675 - val_loss: 0.8519\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6665 - val_loss: 0.8583\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6659 - val_loss: 0.8651\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6656 - val_loss: 0.8744\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6648 - val_loss: 0.8773\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6646 - val_loss: 0.8843\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.6641 - val_loss: 0.8895\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 8ms/step - loss: 0.6638 - val_loss: 0.8963\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6634 - val_loss: 0.9006\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6631 - val_loss: 0.9049\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6629 - val_loss: 0.9102\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6628 - val_loss: 0.9160\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6625 - val_loss: 0.9186\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6623 - val_loss: 0.9225\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6622 - val_loss: 0.9264\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6620 - val_loss: 0.9305\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6619 - val_loss: 0.9343\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6618 - val_loss: 0.9371\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6617 - val_loss: 0.9389\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.6618 - val_loss: 0.9416\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6616 - val_loss: 0.9459\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6615 - val_loss: 0.9486\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6615 - val_loss: 0.9496\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6614 - val_loss: 0.9514\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6614 - val_loss: 0.9528\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6613 - val_loss: 0.9545\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.6613 - val_loss: 0.9570\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.6613 - val_loss: 0.9598\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6613 - val_loss: 0.9629\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6612 - val_loss: 0.9634\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6612 - val_loss: 0.9658\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6612 - val_loss: 0.9671\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6612 - val_loss: 0.9710\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9708\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9722\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9683\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6625 - val_loss: 0.9755\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.6611 - val_loss: 0.9766\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9769\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6611 - val_loss: 0.9757\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6610 - val_loss: 0.9770\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6615 - val_loss: 0.8736\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6583 - val_loss: 0.9567\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6524 - val_loss: 0.9731\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6499 - val_loss: 0.9062\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6397 - val_loss: 0.9084\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6297 - val_loss: 0.8739\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6185 - val_loss: 0.8816\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6048 - val_loss: 0.8215\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5810 - val_loss: 0.9339\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5564 - val_loss: 0.9662\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5420 - val_loss: 0.9959\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5221 - val_loss: 0.9141\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5044 - val_loss: 0.9133\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4902 - val_loss: 0.9537\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4763 - val_loss: 0.9438\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4658 - val_loss: 0.9064\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4565 - val_loss: 0.9486\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4463 - val_loss: 0.9133\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4370 - val_loss: 0.9603\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4273 - val_loss: 1.0188\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4204 - val_loss: 0.9859\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4138 - val_loss: 1.0072\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4076 - val_loss: 0.9915\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4018 - val_loss: 1.0210\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3962 - val_loss: 1.0197\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3909 - val_loss: 1.0305\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3858 - val_loss: 1.0275\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3810 - val_loss: 1.0404\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3762 - val_loss: 1.0462\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3717 - val_loss: 1.0466\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3672 - val_loss: 0.9994\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3609 - val_loss: 1.1084\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3566 - val_loss: 1.0816\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3521 - val_loss: 0.9942\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3472 - val_loss: 1.1010\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3429 - val_loss: 1.0870\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3391 - val_loss: 1.1068\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3355 - val_loss: 1.1142\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3319 - val_loss: 1.1215\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3285 - val_loss: 1.1184\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3252 - val_loss: 1.1347\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3218 - val_loss: 1.1382\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3187 - val_loss: 1.1433\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3156 - val_loss: 1.1514\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3126 - val_loss: 1.1538\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3096 - val_loss: 1.1631\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3068 - val_loss: 1.1656\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3039 - val_loss: 1.1743\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3012 - val_loss: 1.1733\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2985 - val_loss: 1.1886\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2959 - val_loss: 1.1835\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2933 - val_loss: 1.1944\n",
      "\n",
      "Train/Test model SN_628 on Fold #3.\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 0.6898 - val_loss: 0.7393\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6773 - val_loss: 0.7891\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6734 - val_loss: 0.8040\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6719 - val_loss: 0.8174\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6702 - val_loss: 0.8277\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6690 - val_loss: 0.8380\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6681 - val_loss: 0.8487\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6672 - val_loss: 0.8562\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6666 - val_loss: 0.8644\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.6660 - val_loss: 0.8701\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6656 - val_loss: 0.8772\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6651 - val_loss: 0.8838\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6647 - val_loss: 0.8891\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6644 - val_loss: 0.8969\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6640 - val_loss: 0.9018\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6637 - val_loss: 0.9059\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6635 - val_loss: 0.9038\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6623 - val_loss: 0.9026\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6628 - val_loss: 0.8593\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6607 - val_loss: 0.9027\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6562 - val_loss: 0.8873\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6536 - val_loss: 0.8995\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6489 - val_loss: 0.9175\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6420 - val_loss: 0.8895\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6348 - val_loss: 0.8969\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6288 - val_loss: 0.9128\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6191 - val_loss: 0.9181\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6103 - val_loss: 0.9200\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6022 - val_loss: 0.9018\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5964 - val_loss: 0.9324\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5863 - val_loss: 0.9557\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5781 - val_loss: 0.9152\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5711 - val_loss: 0.8927\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5610 - val_loss: 0.9069\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5534 - val_loss: 0.9641\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5427 - val_loss: 0.9605\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5370 - val_loss: 0.9581\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5294 - val_loss: 0.9519\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5234 - val_loss: 0.9508\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5178 - val_loss: 0.9381\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5127 - val_loss: 0.9465\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5076 - val_loss: 0.9646\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5027 - val_loss: 0.9749\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4978 - val_loss: 0.9713\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4932 - val_loss: 0.9911\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4870 - val_loss: 0.9997\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4825 - val_loss: 0.9778\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4782 - val_loss: 0.9870\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4741 - val_loss: 1.0039\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4701 - val_loss: 0.9968\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4661 - val_loss: 0.9928\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4623 - val_loss: 1.0180\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4579 - val_loss: 0.9832\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4541 - val_loss: 0.9914\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4504 - val_loss: 0.9881\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4470 - val_loss: 1.0281\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4440 - val_loss: 1.0812\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4394 - val_loss: 1.0563\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4352 - val_loss: 0.9901\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4319 - val_loss: 1.0088\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4285 - val_loss: 1.0287\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4255 - val_loss: 1.0209\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4224 - val_loss: 1.0328\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4194 - val_loss: 1.0262\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4165 - val_loss: 1.0359\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4137 - val_loss: 1.0317\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4109 - val_loss: 1.0153\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4080 - val_loss: 0.9878\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4036 - val_loss: 0.9534\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4009 - val_loss: 1.0323\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3962 - val_loss: 1.0281\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3945 - val_loss: 1.0782\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3887 - val_loss: 1.0553\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3835 - val_loss: 0.9852\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3810 - val_loss: 1.0948\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3782 - val_loss: 1.0332\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3756 - val_loss: 1.0549\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3730 - val_loss: 1.0454\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3706 - val_loss: 1.0419\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3681 - val_loss: 1.0580\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3666 - val_loss: 1.0659\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3619 - val_loss: 1.0810\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3586 - val_loss: 1.0697\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3564 - val_loss: 1.0808\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3540 - val_loss: 1.0867\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3518 - val_loss: 1.0852\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3496 - val_loss: 1.0771\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3474 - val_loss: 1.0851\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3439 - val_loss: 0.8915\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3460 - val_loss: 1.1193\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3436 - val_loss: 1.0936\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3370 - val_loss: 1.1411\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3346 - val_loss: 0.9801\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3325 - val_loss: 1.1384\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3304 - val_loss: 1.0869\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3283 - val_loss: 1.0560\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3271 - val_loss: 1.1807\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3218 - val_loss: 1.0518\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3196 - val_loss: 1.1223\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3178 - val_loss: 1.1077\n",
      "\n",
      "Train/Test model SN_628 on Fold #4.\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.6897 - val_loss: 0.7337\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6782 - val_loss: 0.7851\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6730 - val_loss: 0.8045\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6713 - val_loss: 0.8162\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6699 - val_loss: 0.8259\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6687 - val_loss: 0.8335\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6679 - val_loss: 0.8441\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6670 - val_loss: 0.8534\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6661 - val_loss: 0.8599\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6655 - val_loss: 0.8685\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6649 - val_loss: 0.8762\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6643 - val_loss: 0.8830\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6638 - val_loss: 0.8884\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6634 - val_loss: 0.8928\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6630 - val_loss: 0.9022\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6627 - val_loss: 0.9087\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6624 - val_loss: 0.9139\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6621 - val_loss: 0.9169\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6620 - val_loss: 0.9228\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.6618 - val_loss: 0.9270\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.6616 - val_loss: 0.9299\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6610 - val_loss: 0.9260\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6593 - val_loss: 0.9047\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6555 - val_loss: 0.9237\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6492 - val_loss: 0.8900\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6409 - val_loss: 0.9104\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6313 - val_loss: 0.8528\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6213 - val_loss: 0.8801\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6087 - val_loss: 0.9295\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6038 - val_loss: 0.8274\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5949 - val_loss: 0.8584\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5796 - val_loss: 0.9361\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5712 - val_loss: 0.9153\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5575 - val_loss: 0.9131\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5475 - val_loss: 0.8935\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5374 - val_loss: 0.8925\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5272 - val_loss: 0.8756\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5185 - val_loss: 0.8711\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5095 - val_loss: 0.9234\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5027 - val_loss: 0.9046\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4937 - val_loss: 0.8798\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4868 - val_loss: 0.8416\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4797 - val_loss: 0.9618\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4706 - val_loss: 0.9288\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4642 - val_loss: 0.9014\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4578 - val_loss: 0.9267\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4520 - val_loss: 0.9555\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4462 - val_loss: 0.9615\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4405 - val_loss: 0.8941\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4343 - val_loss: 0.9275\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4291 - val_loss: 0.9471\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4243 - val_loss: 0.9326\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4197 - val_loss: 0.9267\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4153 - val_loss: 0.9442\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4110 - val_loss: 0.9436\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4068 - val_loss: 0.9466\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4027 - val_loss: 0.9360\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3988 - val_loss: 0.9560\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3949 - val_loss: 0.9493\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3912 - val_loss: 0.9549\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3875 - val_loss: 0.9492\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3840 - val_loss: 0.9709\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3804 - val_loss: 0.9608\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3770 - val_loss: 0.9507\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3737 - val_loss: 0.9665\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3704 - val_loss: 0.9799\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3672 - val_loss: 0.9728\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3640 - val_loss: 0.9769\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3609 - val_loss: 0.9593\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3579 - val_loss: 1.0302\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3542 - val_loss: 0.9067\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3504 - val_loss: 0.9422\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3473 - val_loss: 0.9991\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3444 - val_loss: 0.9635\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3416 - val_loss: 0.9976\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3388 - val_loss: 0.9727\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3361 - val_loss: 0.9933\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3334 - val_loss: 0.9801\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3308 - val_loss: 0.9821\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3283 - val_loss: 0.9862\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3258 - val_loss: 0.9867\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3233 - val_loss: 0.9729\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3208 - val_loss: 1.0001\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3189 - val_loss: 1.1281\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3149 - val_loss: 1.0779\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3110 - val_loss: 0.9034\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3086 - val_loss: 1.0386\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3062 - val_loss: 0.9863\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3039 - val_loss: 1.0164\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3016 - val_loss: 0.9837\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2994 - val_loss: 1.0289\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2972 - val_loss: 1.0057\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2951 - val_loss: 1.0173\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2930 - val_loss: 1.0259\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2910 - val_loss: 1.0098\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2889 - val_loss: 1.0278\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2870 - val_loss: 1.0204\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2850 - val_loss: 1.0229\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2831 - val_loss: 1.0328\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2811 - val_loss: 1.0307\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### For each input file, train model and generate different outputs in a structured folder\n",
    "##################################################################################\n",
    "\n",
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Model\" : [],\n",
    "    \"Kernel_Length\" : [],\n",
    "    \"Dataset\" : [],\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "for root, dirs, files in os.walk(input_data_folder):\n",
    "    for file in files:\n",
    "        \n",
    "        input_data_file = os.path.join(root, file)\n",
    "        \n",
    "        current_dataset_variety = input_data_file.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "        csv_data = pd.read_csv(input_data_file)\n",
    "\n",
    "        ##################################################################################\n",
    "        ##### extract data from the current CSV file\n",
    "        ##################################################################################\n",
    "\n",
    "        csv_data[\"OHE_MergedSeq\"] = pd.Series([one_hot_encode_rna_mergedseq(val) for val in csv_data[\"MergedSeq\"]])\n",
    "\n",
    "        df_positive = csv_data[csv_data['Number'].str.contains(\"P\")]\n",
    "        df_negative = csv_data[csv_data['Number'].str.contains(\"N\")]\n",
    "\n",
    "        positive_onehotencoded_array = np.array(list(df_positive['OHE_MergedSeq']))\n",
    "        negative_onehotencoded_array = np.array(list(df_negative['OHE_MergedSeq']))\n",
    "\n",
    "        print(\"\\n======================================================================\")\n",
    "        print(\"\\nFile:\", input_data_file)\n",
    "        print(\"Positive:\", positive_onehotencoded_array.shape[0])\n",
    "        print(\"Negative:\", negative_onehotencoded_array.shape[0])\n",
    "\n",
    "        ##################################################################################\n",
    "        ##### Generate Folds from dataset, and store to file\n",
    "        ##################################################################################\n",
    "\n",
    "        ## create the features and labels datasets for the training\n",
    "        input_size = positive_onehotencoded_array[0].shape\n",
    "\n",
    "        labels = np.concatenate((np.ones((positive_onehotencoded_array.shape[0], 1), \n",
    "                                         dtype=np.float32), \n",
    "                                 np.zeros((negative_onehotencoded_array.shape[0], 1), \n",
    "                                          dtype=np.float32)), \n",
    "                                axis=0)\n",
    "        \n",
    "        features = np.concatenate((positive_onehotencoded_array, \n",
    "                                   negative_onehotencoded_array), \n",
    "                                  axis=0)\n",
    "        features_required_shape = tuple(list(features.shape) + [1])\n",
    "        features = features.reshape(features_required_shape)\n",
    "        model_input_shape = tuple(list(features.shape[1:]))\n",
    "        \n",
    "        folds = build_kfold(features, labels, \n",
    "                            k=n_fold, shuffle=shuffle, seed=seed)\n",
    "\n",
    "        ## Write the k-fold dataset to file\n",
    "        foldPath = os.path.join(outPath, expName, current_dataset_variety, \"{}fold\".format(n_fold))\n",
    "        if(not os.path.isdir(foldPath)):\n",
    "            os.makedirs(foldPath)\n",
    "        pickle.dump(folds, open(os.path.join(foldPath, foldName), \"wb\"))\n",
    "\n",
    "        ## Create and set directory to save model\n",
    "        modelPath = os.path.join(outPath, expName, current_dataset_variety, \"{}fold\".format(n_fold), \"models\")\n",
    "        if(not os.path.isdir(modelPath)):\n",
    "            os.makedirs(modelPath)\n",
    "\n",
    "        ##################################################################################\n",
    "        ##### TRAIN and PREDICT for every Fold, using models\n",
    "        ##################################################################################\n",
    "\n",
    "        # fold counter\n",
    "        i = 0\n",
    "\n",
    "        for fold in folds:\n",
    "\n",
    "            print(\"\\nTrain/Test model \"+current_dataset_variety+\" on Fold #\"+str(i)+\".\")\n",
    "\n",
    "            kernel_length = 3\n",
    "            ## Generate model using function\n",
    "        #             model = Conv_LSTM_DLNN(input_shape = input_size, conv_filters_per_layer = 50, kernel_length = kernel_length, \n",
    "        #                                    lstm_decode_units = 50, max_pool_width = 2, max_pool_stride = 2, dense_decode_units = 50,\n",
    "        #                                    learn_rate = 0.0001, prob = 0.5, loss='binary_crossentropy', metrics=None)\n",
    "\n",
    "            model = DLNN_MergedSeq_conv2d(input_shape = model_input_shape)\n",
    "\n",
    "            ## Define the model callbacks for early stopping and saving the model. Then train model\n",
    "        #     modelCallbacks = [\n",
    "        #         tf.keras.callbacks.ModelCheckpoint(os.path.join(modelPath, \"{}_bestModel-fold{}.hdf5\".format(current_dataset_variety, i)),\n",
    "        #                                            monitor = 'val_loss', verbose = 1, save_best_only = True, \n",
    "        #                                            save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "        #         tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 10, verbose = 1, \n",
    "        #                                          mode = 'auto', baseline = None, restore_best_weights = False)\n",
    "        #     ]\n",
    "        #     model.fit(x = fold[\"X_train\"], y = fold[\"y_train\"], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "        #               callbacks = modelCallbacks, validation_split=0.2)\n",
    "\n",
    "            model.fit(x = fold[\"X_train\"], y = fold[\"y_train\"], batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "                      validation_split=0.2)\n",
    "\n",
    "            ##################################################################################\n",
    "            ##### Prediction and metrics for TRAIN dataset\n",
    "            ##################################################################################\n",
    "\n",
    "            y_pred = model.predict(fold[\"X_train\"])\n",
    "            label_pred = pred2label(y_pred)\n",
    "            # Compute precision, recall, sensitivity, specifity, mcc\n",
    "            acc = accuracy_score(fold[\"y_train\"], label_pred)\n",
    "            prec = precision_score(fold[\"y_train\"],label_pred)\n",
    "\n",
    "            conf = confusion_matrix(fold[\"y_train\"], label_pred)\n",
    "            if(conf[0][0]+conf[1][0]):\n",
    "                sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "            else:\n",
    "                sens = 0.0\n",
    "            if(conf[1][1]+conf[0][1]):\n",
    "                spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "            else:\n",
    "                spec = 0.0\n",
    "            if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "                mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "            else:\n",
    "                mcc= 0.0\n",
    "            fpr, tpr, thresholds = roc_curve(fold[\"y_train\"], y_pred)\n",
    "            auc = roc_auc_score(fold[\"y_train\"], y_pred)\n",
    "\n",
    "            evaluations[\"Model\"].append(current_dataset_variety)\n",
    "            evaluations[\"Kernel_Length\"].append(kernel_length)\n",
    "            evaluations[\"Dataset\"].append(current_dataset_variety)\n",
    "            evaluations[\"Fold\"].append(i)\n",
    "            evaluations[\"Train_Test\"].append(\"Train\")\n",
    "            evaluations[\"Accuracy\"].append(acc)\n",
    "            evaluations[\"Precision\"].append(prec)\n",
    "            evaluations[\"TPR\"].append(tpr)\n",
    "            evaluations[\"FPR\"].append(fpr)\n",
    "            evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "            evaluations[\"AUC\"].append(auc)\n",
    "            evaluations[\"Sensitivity\"].append(sens)\n",
    "            evaluations[\"Specificity\"].append(spec)\n",
    "            evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "            ##################################################################################\n",
    "            ##### Prediction and metrics for TEST dataset\n",
    "            ##################################################################################\n",
    "\n",
    "            y_pred = model.predict(fold[\"X_test\"])\n",
    "            label_pred = pred2label(y_pred)\n",
    "            # Compute precision, recall, sensitivity, specifity, mcc\n",
    "            acc = accuracy_score(fold[\"y_test\"], label_pred)\n",
    "            prec = precision_score(fold[\"y_test\"],label_pred)\n",
    "\n",
    "            conf = confusion_matrix(fold[\"y_test\"], label_pred)\n",
    "            if(conf[0][0]+conf[1][0]):\n",
    "                sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "            else:\n",
    "                sens = 0.0\n",
    "            if(conf[1][1]+conf[0][1]):\n",
    "                spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "            else:\n",
    "                spec = 0.0\n",
    "            if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "                mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "            else:\n",
    "                mcc= 0.0\n",
    "            fpr, tpr, thresholds = roc_curve(fold[\"y_test\"], y_pred)\n",
    "            auc = roc_auc_score(fold[\"y_test\"], y_pred)\n",
    "\n",
    "            evaluations[\"Model\"].append(current_dataset_variety)\n",
    "            evaluations[\"Kernel_Length\"].append(kernel_length)\n",
    "            evaluations[\"Dataset\"].append(current_dataset_variety)\n",
    "            evaluations[\"Fold\"].append(i)\n",
    "            evaluations[\"Train_Test\"].append(\"Test\")\n",
    "            evaluations[\"Accuracy\"].append(acc)\n",
    "            evaluations[\"Precision\"].append(prec)\n",
    "            evaluations[\"TPR\"].append(tpr)\n",
    "            evaluations[\"FPR\"].append(fpr)\n",
    "            evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "            evaluations[\"AUC\"].append(auc)\n",
    "            evaluations[\"Sensitivity\"].append(sens)\n",
    "            evaluations[\"Specificity\"].append(spec)\n",
    "            evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "            i = i+1\n",
    "            del model\n",
    "            tf.keras.backend.clear_session()\n",
    "\n",
    "        ##################################################################################\n",
    "        ##### Dump evaluations to a file\n",
    "        ##################################################################################\n",
    "\n",
    "        evalPath = os.path.join(outPath, expName, \"_Evaluation_All_Datasets\")\n",
    "        if(not os.path.isdir(evalPath)):\n",
    "            os.makedirs(evalPath)\n",
    "\n",
    "        pickle.dump(evaluations,\n",
    "                    open(os.path.join(evalPath, \"{}fold_evaluations.pickle\".format(n_fold)), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 12, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(list(features.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_required_shape = tuple(list(features.shape) + [1])\n",
    "features = features.reshape(features_required_shape)\n",
    "model_input_shape = tuple(list(features.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 12, 1, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Add import statement here, to make this next part of code standalone executable\n",
    "##################################################################################\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Load file and convert to dataframe for easy manipulation\n",
    "##################################################################################\n",
    "\n",
    "evalPath = os.path.join(outPath, expName, \"_Evaluation_All_Datasets\")\n",
    "if(not os.path.isdir(evalPath)):\n",
    "    os.makedirs(evalPath)\n",
    "\n",
    "evaluations = pickle.load(open(os.path.join(evalPath, \"{}fold_evaluations.pickle\".format(n_fold)), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluations[\"Model\"] = evaluations[\"Model\"][0:20]\n",
    "# evaluations_df = pd.DataFrame.from_dict(evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "##################################################################################\n",
    "##### Group dataset (mean of metrics) by [Dataset, Model, Train_Test] combinations\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Dataset\", \n",
    "                                                 \"Model\", \n",
    "                                                 \"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "# DLNN_3 = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(1), ['DLNN_3'])]\n",
    "# DLNN_5 = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(1), ['DLNN_5'])]\n",
    "\n",
    "# DLNN_3_Train = DLNN_3[np.in1d(DLNN_3.index.get_level_values(2), ['Train'])]\n",
    "# DLNN_3_Test = DLNN_3[np.in1d(DLNN_3.index.get_level_values(2), ['Test'])]\n",
    "\n",
    "# DLNN_5_Train = DLNN_5[np.in1d(DLNN_5.index.get_level_values(2), ['Train'])]\n",
    "# DLNN_5_Test = DLNN_5[np.in1d(DLNN_5.index.get_level_values(2), ['Test'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">HS_990</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">HS_990</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.558586</td>\n",
       "      <td>0.544132</td>\n",
       "      <td>0.591521</td>\n",
       "      <td>0.588537</td>\n",
       "      <td>0.544132</td>\n",
       "      <td>0.124640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train</td>\n",
       "      <td>0.820707</td>\n",
       "      <td>0.743767</td>\n",
       "      <td>0.835369</td>\n",
       "      <td>0.969044</td>\n",
       "      <td>0.743767</td>\n",
       "      <td>0.676159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">MM_944</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">MM_944</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.603833</td>\n",
       "      <td>0.580193</td>\n",
       "      <td>0.671876</td>\n",
       "      <td>0.648608</td>\n",
       "      <td>0.580193</td>\n",
       "      <td>0.217919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train</td>\n",
       "      <td>0.852754</td>\n",
       "      <td>0.785705</td>\n",
       "      <td>0.862407</td>\n",
       "      <td>0.961831</td>\n",
       "      <td>0.785705</td>\n",
       "      <td>0.726200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">SN_628</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">SN_628</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.541410</td>\n",
       "      <td>0.532502</td>\n",
       "      <td>0.562298</td>\n",
       "      <td>0.457048</td>\n",
       "      <td>0.532502</td>\n",
       "      <td>0.086047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train</td>\n",
       "      <td>0.780994</td>\n",
       "      <td>0.720023</td>\n",
       "      <td>0.860845</td>\n",
       "      <td>0.788941</td>\n",
       "      <td>0.720023</td>\n",
       "      <td>0.585008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Accuracy  Precision       AUC  Sensitivity  \\\n",
       "Dataset Model  Train_Test                                               \n",
       "HS_990  HS_990 Test        0.558586   0.544132  0.591521     0.588537   \n",
       "               Train       0.820707   0.743767  0.835369     0.969044   \n",
       "MM_944  MM_944 Test        0.603833   0.580193  0.671876     0.648608   \n",
       "               Train       0.852754   0.785705  0.862407     0.961831   \n",
       "SN_628  SN_628 Test        0.541410   0.532502  0.562298     0.457048   \n",
       "               Train       0.780994   0.720023  0.860845     0.788941   \n",
       "\n",
       "                           Specificity       MCC  \n",
       "Dataset Model  Train_Test                         \n",
       "HS_990  HS_990 Test           0.544132  0.124640  \n",
       "               Train          0.743767  0.676159  \n",
       "MM_944  MM_944 Test           0.580193  0.217919  \n",
       "               Train          0.785705  0.726200  \n",
       "SN_628  SN_628 Test           0.532502  0.086047  \n",
       "               Train          0.720023  0.585008  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# ##### Decide on metric to visualize\n",
    "# ##################################################################################\n",
    "\n",
    "# print(\"Metrics Available : \")\n",
    "# print(list(evaluations_df_grouped.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select a metric to plot below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_to_plot = \"Accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# ##### Visualize with a multiple Bar chart\n",
    "# ##################################################################################\n",
    "\n",
    "# x = np.arange(len(DLNN_3_Train[metric_to_plot]))\n",
    "# width = 0.15\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(17,6))\n",
    "# rects1 = ax.bar(x - (4*(width/2)), round(DLNN_3_Train[metric_to_plot]*100, 3), width, label='DLNN_3, Train')\n",
    "# rects2 = ax.bar(x - (1.5*(width/2)), round(DLNN_5_Train[metric_to_plot]*100, 3), width, label='DLNN_5, Train')\n",
    "# rects3 = ax.bar(x + (1.5*(width/2)), round(DLNN_3_Test[metric_to_plot]*100, 3), width, label='DLNN_3, Test')\n",
    "# rects4 = ax.bar(x + (4*(width/2)), round(DLNN_5_Test[metric_to_plot]*100, 3), width, label='DLNN_5, Test')\n",
    "\n",
    "# ## Custom y-axis tick labels\n",
    "# ax.set_ylabel(metric_to_plot)\n",
    "# ax.set_ylim([(math.floor(min(evaluations_df_grouped[metric_to_plot])*10)-1)*10, \n",
    "#             (math.ceil(max(evaluations_df_grouped[metric_to_plot])*10)+1)*10])\n",
    "# # ax.set_ylim([80, 105])\n",
    "\n",
    "# ## Custom x-axis tick labels\n",
    "# ax.set_xticks(x)\n",
    "# # ax.set_xticklabels(DLNN_3_Train.index.get_level_values(0))\n",
    "# # ax.set_xticklabels([m+\" - \"+str(n) for m,n in \n",
    "# #                         zip(DLNN_3_Train.index.get_level_values(0),DLNN_3_Train.index.get_level_values(1))],\n",
    "# #                   rotation=30)\n",
    "# ax.set_xticklabels(DLNN_3_Train.index.get_level_values(0))\n",
    "\n",
    "# ax.set_title(metric_to_plot+' by Dataset, Model, Train/Test')\n",
    "# ax.legend(loc='upper left')\n",
    "\n",
    "# def autolabel(rects):\n",
    "#     for rect in rects:\n",
    "#         height = rect.get_height()\n",
    "#         ax.annotate('{}'.format(height),\n",
    "#                     xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "#                     xytext=(0, 3),  # 3 points vertical offset\n",
    "#                     textcoords=\"offset points\", \n",
    "#                     ha='center', va='bottom', rotation=90)\n",
    "\n",
    "# autolabel(rects1)\n",
    "# autolabel(rects2)\n",
    "# autolabel(rects3)\n",
    "# autolabel(rects4)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store all metrics' plots to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# ##### Iteratively generate comparison plot using every metric\n",
    "# ##################################################################################\n",
    "\n",
    "# for metric_to_plot in list(evaluations_df_grouped.columns):\n",
    "    \n",
    "#     x = np.arange(len(DLNN_3_Train[metric_to_plot]))\n",
    "#     width = 0.15\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(17,6))\n",
    "#     rects1 = ax.bar(x - (4*(width/2)), round(DLNN_3_Train[metric_to_plot]*100, 3), width, label='DLNN_3, Train')\n",
    "#     rects2 = ax.bar(x - (1.5*(width/2)), round(DLNN_5_Train[metric_to_plot]*100, 3), width, label='DLNN_5, Train')\n",
    "#     rects3 = ax.bar(x + (1.5*(width/2)), round(DLNN_3_Test[metric_to_plot]*100, 3), width, label='DLNN_3, Test')\n",
    "#     rects4 = ax.bar(x + (4*(width/2)), round(DLNN_5_Test[metric_to_plot]*100, 3), width, label='DLNN_5, Test')\n",
    "\n",
    "#     ## Custom y-axis tick labels\n",
    "#     ax.set_ylabel(metric_to_plot)\n",
    "#     ax.set_ylim([(math.floor(min(evaluations_df_grouped[metric_to_plot])*10)-1)*10, \n",
    "#                 (math.ceil(max(evaluations_df_grouped[metric_to_plot])*10)+1)*10])\n",
    "#     # ax.set_ylim([80, 105])\n",
    "\n",
    "#     ## Custom x-axis tick labels\n",
    "#     ax.set_xticks(x)\n",
    "#     # ax.set_xticklabels(DLNN_3_Train.index.get_level_values(0))\n",
    "#     # ax.set_xticklabels([m+\" - \"+str(n) for m,n in \n",
    "#     #                         zip(DLNN_3_Train.index.get_level_values(0),DLNN_3_Train.index.get_level_values(1))],\n",
    "#     #                   rotation=30)\n",
    "#     ax.set_xticklabels(DLNN_3_Train.index.get_level_values(0))\n",
    "\n",
    "#     ax.set_title(metric_to_plot+' by Dataset, Model, Train/Test')\n",
    "#     ax.legend(loc='upper left')\n",
    "\n",
    "#     def autolabel(rects):\n",
    "#         for rect in rects:\n",
    "#             height = rect.get_height()\n",
    "#             ax.annotate('{}'.format(height),\n",
    "#                         xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "#                         xytext=(0, 3),  # 3 points vertical offset\n",
    "#                         textcoords=\"offset points\", \n",
    "#                         ha='center', va='bottom', rotation=90)\n",
    "\n",
    "#     autolabel(rects1)\n",
    "#     autolabel(rects2)\n",
    "#     autolabel(rects3)\n",
    "#     autolabel(rects4)\n",
    "    \n",
    "#     plt.savefig(os.path.join(evalPath, \"{}_DLNN_Comparison\".format(metric_to_plot)))\n",
    "#     plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

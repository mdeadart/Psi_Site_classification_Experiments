{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Define all parameters for model tuning\n",
    "##################################################################################\n",
    "\n",
    "n_fold = 5\n",
    "expName = \"PSI_Site_DLNN_MergedSeq_autoencoder\"\n",
    "outPath = \"Results\"\n",
    "foldName = \"folds.pickle\"\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "shuffle = False\n",
    "seed = None\n",
    "\n",
    "\n",
    "input_data_folder = \"Data\\\\Aziz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from Bio import SeqIO\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# print(tf.test.is_gpu_available(cuda_only=True))\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define all CUSTOM functions\n",
    "##################################################################################\n",
    "\n",
    "def one_hot_encode_dna(sequence):\n",
    "    seq_encoded = np.zeros((len(sequence),4))\n",
    "    dict_nuc = {\n",
    "        \"A\": 0,\n",
    "        \"C\": 1,\n",
    "        \"G\": 2,\n",
    "        \"T\": 3\n",
    "    }\n",
    "    i = 0\n",
    "    for single_character in sequence:\n",
    "        if(single_character.upper() in dict_nuc.keys()):\n",
    "            seq_encoded[i][dict_nuc[single_character.upper()]] = 1\n",
    "            i = i+1\n",
    "        else:\n",
    "            raise ValueError('Incorrect character in DNA sequence: '+sequence)\n",
    "    return seq_encoded\n",
    "\n",
    "def one_hot_encode_rna(sequence):\n",
    "    seq_encoded = np.zeros((len(sequence),4))\n",
    "    dict_nuc = {\n",
    "        \"A\": 0,\n",
    "        \"C\": 1,\n",
    "        \"G\": 2,\n",
    "        \"U\": 3\n",
    "    }\n",
    "    i = 0\n",
    "    for single_character in sequence:\n",
    "        if(single_character.upper() in dict_nuc.keys()):\n",
    "            seq_encoded[i][dict_nuc[single_character.upper()]] = 1\n",
    "            i = i+1\n",
    "        else:\n",
    "            raise ValueError('Incorrect character in RNA sequence: '+sequence)\n",
    "    return seq_encoded\n",
    "\n",
    "def one_hot_encode_rnafold(sequence):\n",
    "    seq_encoded = np.zeros((len(sequence),3))\n",
    "    dict_fold = {\n",
    "        \"(\": 0,\n",
    "        \")\": 1,\n",
    "        \".\": 2\n",
    "    }\n",
    "    i = 0\n",
    "    for single_character in sequence:\n",
    "        if(single_character in dict_fold.keys()):\n",
    "            seq_encoded[i][dict_fold[single_character]] = 1\n",
    "            i = i+1\n",
    "        else:\n",
    "            raise ValueError('Incorrect character in RNAfold: '+sequence)\n",
    "    return seq_encoded\n",
    "\n",
    "def one_hot_encode_rna_mergedseq(sequence):\n",
    "    dict_nuc = {\n",
    "        \"A\": 0,\n",
    "        \"C\": 1,\n",
    "        \"G\": 2,\n",
    "        \"U\": 3\n",
    "    }\n",
    "    dict_fold = {\n",
    "        \"(\": 0,\n",
    "        \")\": 1,\n",
    "        \".\": 2\n",
    "    }\n",
    "    list_seq = sequence.strip().split(' ')\n",
    "    seq_encoded = np.zeros((len(list_seq),12))\n",
    "    i = 0\n",
    "    for single_character in list_seq:\n",
    "        if(single_character[0].upper() in dict_nuc.keys()):\n",
    "            idx1 = dict_nuc[single_character[0].upper()]+1\n",
    "        else:\n",
    "            raise ValueError('Incorrect RNA character in MergedSeq sequence: '+sequence)\n",
    "        if(single_character[1] in dict_fold.keys()):\n",
    "            idx2 = dict_fold[single_character[1]]+1\n",
    "        else:\n",
    "            raise ValueError('Incorrect RNAfold character in MergedSeq sequence: '+sequence)\n",
    "        idx = (idx1 * idx2) - 1\n",
    "        seq_encoded[i][idx] = 1\n",
    "        i = i+1        \n",
    "    return seq_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define evaluator functions\n",
    "##################################################################################\n",
    "\n",
    "## Build the K-fold from dataset\n",
    "def build_kfold(features, labels, k=10, shuffle=False, seed=None):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "    kfoldList = []\n",
    "    for train_index, test_index in skf.split(features, labels):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        kfoldList.append({\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\":y_train,\n",
    "            \"y_test\":y_test\n",
    "        })\n",
    "    return kfoldList\n",
    "\n",
    "def build_kfold_multifeature(features_1, features_2, labels, k=10, shuffle=False, seed=None):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "    kfoldList = []\n",
    "    for train_index, test_index in skf.split(features_1, labels):\n",
    "        X1_train, X1_test = features_1[train_index], features_1[test_index]\n",
    "        X2_train, X2_test = features_2[train_index], features_2[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        kfoldList.append({\n",
    "            \"X1_train\": X1_train,\n",
    "            \"X1_test\": X1_test,\n",
    "            \"X2_train\": X2_train,\n",
    "            \"X2_test\": X2_test,\n",
    "            \"y_train\":y_train,\n",
    "            \"y_test\":y_test\n",
    "        })\n",
    "    return kfoldList\n",
    "\n",
    "def pred2label(y_pred):\n",
    "    y_pred = np.round(np.clip(y_pred, 0, 1))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Function to customize the DLNN architecture with parameters\n",
    "##################################################################################\n",
    "\n",
    "def DLNN_AutoEncoder_Classifier(input_shape = (21,12), output_shape = (21, 4)):\n",
    "    \n",
    "    \n",
    "    ae_input = tf.keras.layers.Input(shape=input_shape)\n",
    "    \n",
    "    ###########################################################################\n",
    "    ##### Encoder\n",
    "    ###########################################################################\n",
    "    \n",
    "    encoder = tf.keras.models.Sequential()\n",
    "    encoder.add(tf.keras.layers.Flatten(input_shape = input_shape))\n",
    "    encoder.add(tf.keras.layers.Dense(100))\n",
    "    encoder.add(tf.keras.layers.Dense(3))\n",
    "    \n",
    "    ###########################################################################\n",
    "    ##### Decoder\n",
    "    ###########################################################################\n",
    "    \n",
    "    decoder = tf.keras.models.Sequential()\n",
    "    decoder.add(tf.keras.layers.Dense(100, input_shape=(3,)))\n",
    "    decoder.add(tf.keras.layers.Dense(output_shape[0]*output_shape[1]))\n",
    "    decoder.add(tf.keras.layers.Reshape(output_shape))\n",
    "    \n",
    "    ###########################################################################\n",
    "    ##### Classifier\n",
    "    ###########################################################################\n",
    "    \n",
    "    classifier = tf.keras.models.Sequential()\n",
    "    classifier.add(tf.keras.layers.Dense(10, input_shape=(3,)))\n",
    "    classifier.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    ###########################################################################\n",
    "    ##### Total Network\n",
    "    ###########################################################################\n",
    "    \n",
    "    autoencoder = tf.keras.models.Model(ae_input, [decoder(encoder(ae_input)), classifier(encoder(ae_input))])\n",
    "    \n",
    "    autoencoder.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), \n",
    "                        loss=['mean_squared_error', 'binary_crossentropy'], \n",
    "                        metrics='accuracy')\n",
    "    \n",
    "    return autoencoder, encoder, decoder, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "File: Data\\Aziz\\HS_990.csv\n",
      "Positive: 495\n",
      "Negative: 495\n",
      "\n",
      "Train/Test model HS_990 on Fold #0.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-0ad19fab1dc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDLNN_AutoEncoder_Classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             model.fit(x = fold[\"X1_train\"], y = [fold[\"X1_train\"], fold[\"y_train\"]], \n\u001b[0m\u001b[0;32m    101\u001b[0m                       \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                       verbose = 1, validation_split=0.2)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### For each input file, train model and generate different outputs in a structured folder\n",
    "##################################################################################\n",
    "\n",
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Model\" : [],\n",
    "    \"Kernel_Length\" : [],\n",
    "    \"Dataset\" : [],\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "for root, dirs, files in os.walk(input_data_folder):\n",
    "    for file in files:\n",
    "        \n",
    "        input_data_file = os.path.join(root, file)\n",
    "        \n",
    "        current_dataset_variety = input_data_file.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "        csv_data = pd.read_csv(input_data_file)\n",
    "\n",
    "        ##################################################################################\n",
    "        ##### extract data from the current CSV file\n",
    "        ##################################################################################\n",
    "        \n",
    "        csv_data[\"OHE\"] = pd.Series([one_hot_encode_rna(val) for val in csv_data[\"Sequence\"]])\n",
    "        csv_data[\"OHE_MergedSeq\"] = pd.Series([one_hot_encode_rna_mergedseq(val) for val in csv_data[\"MergedSeq\"]])\n",
    "\n",
    "        df_positive = csv_data[csv_data['Number'].str.contains(\"P\")]\n",
    "        df_negative = csv_data[csv_data['Number'].str.contains(\"N\")]\n",
    "\n",
    "        positive_ohe_mergedseq = np.array(list(df_positive['OHE_MergedSeq']))\n",
    "        negative_ohe_mergedseq = np.array(list(df_negative['OHE_MergedSeq']))\n",
    "        \n",
    "        positive_ohe_seq = np.array(list(df_positive['OHE']))\n",
    "        negative_ohe_seq = np.array(list(df_negative['OHE']))\n",
    "\n",
    "        print(\"\\n======================================================================\")\n",
    "        print(\"\\nFile:\", input_data_file)\n",
    "        print(\"Positive:\", positive_ohe_mergedseq.shape[0])\n",
    "        print(\"Negative:\", negative_ohe_mergedseq.shape[0])\n",
    "\n",
    "        ##################################################################################\n",
    "        ##### Generate Folds from dataset, and store to file\n",
    "        ##################################################################################\n",
    "\n",
    "        ## create the features and labels datasets for the training\n",
    "        input_size = positive_ohe_mergedseq[0].shape\n",
    "\n",
    "        labels = np.concatenate((np.ones((df_positive.shape[0], 1), \n",
    "                                         dtype=np.float32), \n",
    "                                 np.zeros((df_negative.shape[0], 1), \n",
    "                                          dtype=np.float32)), \n",
    "                                axis=0)\n",
    "        features_mergedseq = np.concatenate((positive_ohe_mergedseq, \n",
    "                                             negative_ohe_mergedseq), \n",
    "                                            axis=0)\n",
    "        \n",
    "        features_seq = np.concatenate((positive_ohe_seq, \n",
    "                                       negative_ohe_seq), \n",
    "                                      axis=0)\n",
    "\n",
    "        folds = build_kfold_multifeature(features_mergedseq, features_seq, labels, \n",
    "                                         k=n_fold, shuffle=shuffle, seed=seed)\n",
    "\n",
    "#         ## Write the k-fold dataset to file\n",
    "#         foldPath = os.path.join(outPath, expName, current_dataset_variety, \"{}fold\".format(n_fold))\n",
    "#         if(not os.path.isdir(foldPath)):\n",
    "#             os.makedirs(foldPath)\n",
    "#         pickle.dump(folds, open(os.path.join(foldPath, foldName), \"wb\"))\n",
    "\n",
    "#         ## Create and set directory to save model\n",
    "#         modelPath = os.path.join(outPath, expName, current_dataset_variety, \"{}fold\".format(n_fold), \"models\")\n",
    "#         if(not os.path.isdir(modelPath)):\n",
    "#             os.makedirs(modelPath)\n",
    "\n",
    "        ##################################################################################\n",
    "        ##### TRAIN and PREDICT for every Fold, using models\n",
    "        ##################################################################################\n",
    "\n",
    "        # fold counter\n",
    "        i = 0\n",
    "\n",
    "        for fold in folds:\n",
    "\n",
    "            print(\"\\nTrain/Test model \"+current_dataset_variety+\" on Fold #\"+str(i)+\".\")\n",
    "            \n",
    "            model, encoder, decoder, classifier = DLNN_AutoEncoder_Classifier()\n",
    "\n",
    "            model.fit(x = fold[\"X1_train\"], y = [fold[\"X1_train\"], fold[\"y_train\"]], \n",
    "                      batch_size = batch_size, epochs = epochs, \n",
    "                      verbose = 1, validation_split=0.2)\n",
    "\n",
    "            ##################################################################################\n",
    "            ##### Prediction and metrics for TRAIN dataset\n",
    "            ##################################################################################\n",
    "\n",
    "            y_seq, y_pred = model.predict(fold[\"X1_train\"])\n",
    "            label_pred = pred2label(y_pred)\n",
    "            # Compute precision, recall, sensitivity, specifity, mcc\n",
    "            acc = accuracy_score(fold[\"y_train\"], label_pred)\n",
    "            prec = precision_score(fold[\"y_train\"],label_pred)\n",
    "\n",
    "            conf = confusion_matrix(fold[\"y_train\"], label_pred)\n",
    "            if(conf[0][0]+conf[1][0]):\n",
    "                sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "            else:\n",
    "                sens = 0.0\n",
    "            if(conf[1][1]+conf[0][1]):\n",
    "                spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "            else:\n",
    "                spec = 0.0\n",
    "            if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "                mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "            else:\n",
    "                mcc= 0.0\n",
    "            fpr, tpr, thresholds = roc_curve(fold[\"y_train\"], y_pred)\n",
    "            auc = roc_auc_score(fold[\"y_train\"], y_pred)\n",
    "\n",
    "            evaluations[\"Model\"].append(current_dataset_variety)\n",
    "            evaluations[\"Kernel_Length\"].append(kernel_length)\n",
    "            evaluations[\"Dataset\"].append(current_dataset_variety)\n",
    "            evaluations[\"Fold\"].append(i)\n",
    "            evaluations[\"Train_Test\"].append(\"Train\")\n",
    "            evaluations[\"Accuracy\"].append(acc)\n",
    "            evaluations[\"Precision\"].append(prec)\n",
    "            evaluations[\"TPR\"].append(tpr)\n",
    "            evaluations[\"FPR\"].append(fpr)\n",
    "            evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "            evaluations[\"AUC\"].append(auc)\n",
    "            evaluations[\"Sensitivity\"].append(sens)\n",
    "            evaluations[\"Specificity\"].append(spec)\n",
    "            evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "            ##################################################################################\n",
    "            ##### Prediction and metrics for TEST dataset\n",
    "            ##################################################################################\n",
    "\n",
    "            y_seq, y_pred = model.predict(fold[\"X1_test\"])\n",
    "            label_pred = pred2label(y_pred)\n",
    "            # Compute precision, recall, sensitivity, specifity, mcc\n",
    "            acc = accuracy_score(fold[\"y_test\"], label_pred)\n",
    "            prec = precision_score(fold[\"y_test\"],label_pred)\n",
    "\n",
    "            conf = confusion_matrix(fold[\"y_test\"], label_pred)\n",
    "            if(conf[0][0]+conf[1][0]):\n",
    "                sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "            else:\n",
    "                sens = 0.0\n",
    "            if(conf[1][1]+conf[0][1]):\n",
    "                spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "            else:\n",
    "                spec = 0.0\n",
    "            if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "                mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "            else:\n",
    "                mcc= 0.0\n",
    "            fpr, tpr, thresholds = roc_curve(fold[\"y_test\"], y_pred)\n",
    "            auc = roc_auc_score(fold[\"y_test\"], y_pred)\n",
    "\n",
    "            evaluations[\"Model\"].append(current_dataset_variety)\n",
    "            evaluations[\"Kernel_Length\"].append(kernel_length)\n",
    "            evaluations[\"Dataset\"].append(current_dataset_variety)\n",
    "            evaluations[\"Fold\"].append(i)\n",
    "            evaluations[\"Train_Test\"].append(\"Test\")\n",
    "            evaluations[\"Accuracy\"].append(acc)\n",
    "            evaluations[\"Precision\"].append(prec)\n",
    "            evaluations[\"TPR\"].append(tpr)\n",
    "            evaluations[\"FPR\"].append(fpr)\n",
    "            evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "            evaluations[\"AUC\"].append(auc)\n",
    "            evaluations[\"Sensitivity\"].append(sens)\n",
    "            evaluations[\"Specificity\"].append(spec)\n",
    "            evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "            i = i+1\n",
    "            del model\n",
    "            tf.keras.backend.clear_session()\n",
    "\n",
    "        ##################################################################################\n",
    "        ##### Dump evaluations to a file\n",
    "        ##################################################################################\n",
    "\n",
    "#         evalPath = os.path.join(outPath, expName, \"_Evaluation_All_Datasets\")\n",
    "#         if(not os.path.isdir(evalPath)):\n",
    "#             os.makedirs(evalPath)\n",
    "\n",
    "#         pickle.dump(evaluations,\n",
    "#                     open(os.path.join(evalPath, \"{}fold_evaluations.pickle\".format(n_fold)), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# ##### Add import statement here, to make this next part of code standalone executable\n",
    "# ##################################################################################\n",
    "\n",
    "# import os\n",
    "# import pickle\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import ScalarFormatter, FormatStrFormatter\n",
    "# import numpy as np\n",
    "# import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# ##### Load file and convert to dataframe for easy manipulation\n",
    "# ##################################################################################\n",
    "\n",
    "# evalPath = os.path.join(outPath, expName, \"_Evaluation_All_Datasets\")\n",
    "# if(not os.path.isdir(evalPath)):\n",
    "#     os.makedirs(evalPath)\n",
    "\n",
    "# evaluations = pickle.load(open(os.path.join(evalPath, \"{}fold_evaluations.pickle\".format(n_fold)), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluations[\"Model\"] = evaluations[\"Model\"][0:20]\n",
    "# evaluations_df = pd.DataFrame.from_dict(evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "##################################################################################\n",
    "##### Group dataset (mean of metrics) by [Dataset, Model, Train_Test] combinations\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Dataset\", \n",
    "                                                 \"Model\", \n",
    "                                                 \"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "# DLNN_3 = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(1), ['DLNN_3'])]\n",
    "# DLNN_5 = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(1), ['DLNN_5'])]\n",
    "\n",
    "# DLNN_3_Train = DLNN_3[np.in1d(DLNN_3.index.get_level_values(2), ['Train'])]\n",
    "# DLNN_3_Test = DLNN_3[np.in1d(DLNN_3.index.get_level_values(2), ['Test'])]\n",
    "\n",
    "# DLNN_5_Train = DLNN_5[np.in1d(DLNN_5.index.get_level_values(2), ['Train'])]\n",
    "# DLNN_5_Test = DLNN_5[np.in1d(DLNN_5.index.get_level_values(2), ['Test'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">HS_990</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">HS_990</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.573737</td>\n",
       "      <td>0.553526</td>\n",
       "      <td>0.598021</td>\n",
       "      <td>0.623792</td>\n",
       "      <td>0.553526</td>\n",
       "      <td>0.161572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train</td>\n",
       "      <td>0.872475</td>\n",
       "      <td>0.797975</td>\n",
       "      <td>0.927289</td>\n",
       "      <td>0.998649</td>\n",
       "      <td>0.797975</td>\n",
       "      <td>0.770316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">MM_944</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">MM_944</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.631358</td>\n",
       "      <td>0.603158</td>\n",
       "      <td>0.682538</td>\n",
       "      <td>0.684545</td>\n",
       "      <td>0.603158</td>\n",
       "      <td>0.274942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train</td>\n",
       "      <td>0.894071</td>\n",
       "      <td>0.827675</td>\n",
       "      <td>0.947606</td>\n",
       "      <td>0.994769</td>\n",
       "      <td>0.827675</td>\n",
       "      <td>0.805095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">SN_628</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">SN_628</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.546184</td>\n",
       "      <td>0.533210</td>\n",
       "      <td>0.597820</td>\n",
       "      <td>0.576655</td>\n",
       "      <td>0.533210</td>\n",
       "      <td>0.100670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train</td>\n",
       "      <td>0.878178</td>\n",
       "      <td>0.804223</td>\n",
       "      <td>0.957775</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.804223</td>\n",
       "      <td>0.779913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Accuracy  Precision       AUC  Sensitivity  \\\n",
       "Dataset Model  Train_Test                                               \n",
       "HS_990  HS_990 Test        0.573737   0.553526  0.598021     0.623792   \n",
       "               Train       0.872475   0.797975  0.927289     0.998649   \n",
       "MM_944  MM_944 Test        0.631358   0.603158  0.682538     0.684545   \n",
       "               Train       0.894071   0.827675  0.947606     0.994769   \n",
       "SN_628  SN_628 Test        0.546184   0.533210  0.597820     0.576655   \n",
       "               Train       0.878178   0.804223  0.957775     1.000000   \n",
       "\n",
       "                           Specificity       MCC  \n",
       "Dataset Model  Train_Test                         \n",
       "HS_990  HS_990 Test           0.553526  0.161572  \n",
       "               Train          0.797975  0.770316  \n",
       "MM_944  MM_944 Test           0.603158  0.274942  \n",
       "               Train          0.827675  0.805095  \n",
       "SN_628  SN_628 Test           0.533210  0.100670  \n",
       "               Train          0.804223  0.779913  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# ##### Decide on metric to visualize\n",
    "# ##################################################################################\n",
    "\n",
    "# print(\"Metrics Available : \")\n",
    "# print(list(evaluations_df_grouped.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select a metric to plot below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_to_plot = \"Accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# ##### Visualize with a multiple Bar chart\n",
    "# ##################################################################################\n",
    "\n",
    "# x = np.arange(len(DLNN_3_Train[metric_to_plot]))\n",
    "# width = 0.15\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(17,6))\n",
    "# rects1 = ax.bar(x - (4*(width/2)), round(DLNN_3_Train[metric_to_plot]*100, 3), width, label='DLNN_3, Train')\n",
    "# rects2 = ax.bar(x - (1.5*(width/2)), round(DLNN_5_Train[metric_to_plot]*100, 3), width, label='DLNN_5, Train')\n",
    "# rects3 = ax.bar(x + (1.5*(width/2)), round(DLNN_3_Test[metric_to_plot]*100, 3), width, label='DLNN_3, Test')\n",
    "# rects4 = ax.bar(x + (4*(width/2)), round(DLNN_5_Test[metric_to_plot]*100, 3), width, label='DLNN_5, Test')\n",
    "\n",
    "# ## Custom y-axis tick labels\n",
    "# ax.set_ylabel(metric_to_plot)\n",
    "# ax.set_ylim([(math.floor(min(evaluations_df_grouped[metric_to_plot])*10)-1)*10, \n",
    "#             (math.ceil(max(evaluations_df_grouped[metric_to_plot])*10)+1)*10])\n",
    "# # ax.set_ylim([80, 105])\n",
    "\n",
    "# ## Custom x-axis tick labels\n",
    "# ax.set_xticks(x)\n",
    "# # ax.set_xticklabels(DLNN_3_Train.index.get_level_values(0))\n",
    "# # ax.set_xticklabels([m+\" - \"+str(n) for m,n in \n",
    "# #                         zip(DLNN_3_Train.index.get_level_values(0),DLNN_3_Train.index.get_level_values(1))],\n",
    "# #                   rotation=30)\n",
    "# ax.set_xticklabels(DLNN_3_Train.index.get_level_values(0))\n",
    "\n",
    "# ax.set_title(metric_to_plot+' by Dataset, Model, Train/Test')\n",
    "# ax.legend(loc='upper left')\n",
    "\n",
    "# def autolabel(rects):\n",
    "#     for rect in rects:\n",
    "#         height = rect.get_height()\n",
    "#         ax.annotate('{}'.format(height),\n",
    "#                     xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "#                     xytext=(0, 3),  # 3 points vertical offset\n",
    "#                     textcoords=\"offset points\", \n",
    "#                     ha='center', va='bottom', rotation=90)\n",
    "\n",
    "# autolabel(rects1)\n",
    "# autolabel(rects2)\n",
    "# autolabel(rects3)\n",
    "# autolabel(rects4)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store all metrics' plots to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# ##### Iteratively generate comparison plot using every metric\n",
    "# ##################################################################################\n",
    "\n",
    "# for metric_to_plot in list(evaluations_df_grouped.columns):\n",
    "    \n",
    "#     x = np.arange(len(DLNN_3_Train[metric_to_plot]))\n",
    "#     width = 0.15\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(17,6))\n",
    "#     rects1 = ax.bar(x - (4*(width/2)), round(DLNN_3_Train[metric_to_plot]*100, 3), width, label='DLNN_3, Train')\n",
    "#     rects2 = ax.bar(x - (1.5*(width/2)), round(DLNN_5_Train[metric_to_plot]*100, 3), width, label='DLNN_5, Train')\n",
    "#     rects3 = ax.bar(x + (1.5*(width/2)), round(DLNN_3_Test[metric_to_plot]*100, 3), width, label='DLNN_3, Test')\n",
    "#     rects4 = ax.bar(x + (4*(width/2)), round(DLNN_5_Test[metric_to_plot]*100, 3), width, label='DLNN_5, Test')\n",
    "\n",
    "#     ## Custom y-axis tick labels\n",
    "#     ax.set_ylabel(metric_to_plot)\n",
    "#     ax.set_ylim([(math.floor(min(evaluations_df_grouped[metric_to_plot])*10)-1)*10, \n",
    "#                 (math.ceil(max(evaluations_df_grouped[metric_to_plot])*10)+1)*10])\n",
    "#     # ax.set_ylim([80, 105])\n",
    "\n",
    "#     ## Custom x-axis tick labels\n",
    "#     ax.set_xticks(x)\n",
    "#     # ax.set_xticklabels(DLNN_3_Train.index.get_level_values(0))\n",
    "#     # ax.set_xticklabels([m+\" - \"+str(n) for m,n in \n",
    "#     #                         zip(DLNN_3_Train.index.get_level_values(0),DLNN_3_Train.index.get_level_values(1))],\n",
    "#     #                   rotation=30)\n",
    "#     ax.set_xticklabels(DLNN_3_Train.index.get_level_values(0))\n",
    "\n",
    "#     ax.set_title(metric_to_plot+' by Dataset, Model, Train/Test')\n",
    "#     ax.legend(loc='upper left')\n",
    "\n",
    "#     def autolabel(rects):\n",
    "#         for rect in rects:\n",
    "#             height = rect.get_height()\n",
    "#             ax.annotate('{}'.format(height),\n",
    "#                         xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "#                         xytext=(0, 3),  # 3 points vertical offset\n",
    "#                         textcoords=\"offset points\", \n",
    "#                         ha='center', va='bottom', rotation=90)\n",
    "\n",
    "#     autolabel(rects1)\n",
    "#     autolabel(rects2)\n",
    "#     autolabel(rects3)\n",
    "#     autolabel(rects4)\n",
    "    \n",
    "#     plt.savefig(os.path.join(evalPath, \"{}_DLNN_Comparison\".format(metric_to_plot)))\n",
    "#     plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Define the encoding hyperparameters\n",
    "##################################################################################\n",
    "\n",
    "# k-mer config\n",
    "kmer = 5\n",
    "\n",
    "# Tsallis Entropic Parameter\n",
    "tep = 0\n",
    "\n",
    "# threshold\n",
    "th = 10\n",
    "\n",
    "## sliding-window\n",
    "sw = 5\n",
    "\n",
    "## window-step\n",
    "ws = 1\n",
    "\n",
    "##################################################################################\n",
    "##### Define all parameters for model tuning\n",
    "##################################################################################\n",
    "\n",
    "n_fold = 10\n",
    "\n",
    "input_data_folder = \"Data\"\n",
    "input_dataset = \"Psi_Site_Chen\"\n",
    "\n",
    "output_data_folder = \"Data\"\n",
    "output_dataset = \"Psi_Site_Chen_MathFeature_Latest_{}_{}_{}_{}_{}\".format(kmer, tep, th, sw, ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Checking the directory\n",
    "##################################################################################\n",
    "\n",
    "dataset_setting_path = os.path.join(input_data_folder, input_dataset)\n",
    "dataset_varieties = next(os.walk(dataset_setting_path))\n",
    "print(dataset_varieties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(dataset_setting_path):\n",
    "    for file in files:\n",
    "        print((root, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### To eliminate any noise from the sequences (e.g., other letters as: N, K, â€¦)\n",
    "##################################################################################\n",
    "\n",
    "out_path_datasets = os.path.join(output_data_folder, output_dataset)\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_setting_path):\n",
    "    for file in files:\n",
    "        \n",
    "        current_dataset_variety = root.split(\"\\\\\")[len(root.split(\"\\\\\"))-1]\n",
    "        \n",
    "        read_file_full_path = os.path.join(root, file)\n",
    "        write_file_path = root.replace(input_dataset, output_dataset)\n",
    "        write_file_full_path = os.path.join(write_file_path, file)\n",
    "        \n",
    "        if(not os.path.isdir(write_file_path)):\n",
    "            os.makedirs(write_file_path)\n",
    "        \n",
    "        command = \"python MathFeature_Latest/preprocessing/preprocessing.py -i {} -o {}\".format(read_file_full_path, write_file_full_path)\n",
    "        os.system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessed file list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_files_list = []\n",
    "for root, dirs, files in os.walk(out_path_datasets):\n",
    "    for file in files:\n",
    "        if os.path.splitext(file)[-1] == \".txt\":\n",
    "            preprocessed_files_list.append((root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed_files_list = [('Generated\\\\{}_setting1\\\\Datasets\\\\Setting1\\\\Drosophila',\n",
    "#   'nucleosomes_vs_linkers_melanogaster.txt'),\n",
    "#  ('Generated\\\\{}_setting1\\\\Datasets\\\\Setting1\\\\Elegans',\n",
    "#   'nucleosomes_vs_linkers_elegans.txt'),\n",
    "#  ('Generated\\\\{}_setting1\\\\Datasets\\\\Setting1\\\\Homo_Sapiens',\n",
    "#   'nucleosomes_vs_linkers_sapiens.txt'),\n",
    "#  ('Generated\\\\{}_setting1\\\\Datasets\\\\Setting1\\\\Yeast',\n",
    "#   'nucleosomes_vs_linkers_yeast.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_files_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (root, file) in preprocessed_files_list:\n",
    "    \n",
    "    current_dataset_variety = root.split(\"\\\\\")[len(root.split(\"\\\\\"))-1]\n",
    "    input_file_full_path = os.path.join(root, file)\n",
    "\n",
    "    !python MathFeature_Latest/methods/MappingClass_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_NM-binary.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -r 1\n",
    "    !python MathFeature_Latest/methods/MappingClass_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_NM-zcurve.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -r 2\n",
    "    !python MathFeature_Latest/methods/MappingClass_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_NM-real.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -r 3\n",
    "    !python MathFeature_Latest/methods/MappingClass_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_NM-integer.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -r 4\n",
    "    !python MathFeature_Latest/methods/MappingClass_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_NM-eiip.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -r 5\n",
    "    !python MathFeature_Latest/methods/MappingClass_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_NM-complex.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -r 6\n",
    "    !python MathFeature_Latest/methods/MappingClass_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_NM-atomic.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -r 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Mapping - Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (root, file) in preprocessed_files_list:\n",
    "    \n",
    "    current_dataset_variety = root.split(\"\\\\\")[len(root.split(\"\\\\\"))-1]\n",
    "    input_file_full_path = os.path.join(root, file)\n",
    "\n",
    "    !python MathFeature_Latest/methods/FourierClass_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_NMFT-binary.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -r 1\n",
    "    !python MathFeature_Latest/methods/FourierClass_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_NMFT-zcurve.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -r 2\n",
    "    !python MathFeature_Latest/methods/FourierClass_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_NMFT-real.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -r 3\n",
    "    !python MathFeature_Latest/methods/FourierClass_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_NMFT-integer.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -r 4\n",
    "    !python MathFeature_Latest/methods/FourierClass_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_NMFT-eiip.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -r 5\n",
    "    !python MathFeature_Latest/methods/FourierClass_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_NMFT-complex.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -r 6\n",
    "    !python MathFeature_Latest/methods/FourierClass_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_NMFT-atomic.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -r 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaos Game Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some options use kmer\n",
    "\n",
    "for (root, file) in preprocessed_files_list:\n",
    "    \n",
    "    current_dataset_variety = root.split(\"\\\\\")[len(root.split(\"\\\\\"))-1]\n",
    "    input_file_full_path = os.path.join(root, file)\n",
    "    \n",
    "    !python MathFeature_Latest/methods/ChaosGameTheory_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_Chaos-classic.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -r 1\n",
    "#     !python MathFeature_Latest/methods/ChaosGameTheory_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_Chaos-frequency.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -r 2 -f {kmer}\n",
    "    !python MathFeature_Latest/methods/ChaosGameTheory_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_Chaos-classic-signal.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -r 3\n",
    "#     !python MathFeature_Latest/methods/ChaosGameTheory_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_Chaos-frequency-signal.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -r 4 -f {kmer}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy - Shannon and Tsallis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shannon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uses kmer\n",
    "\n",
    "for (root, file) in preprocessed_files_list:\n",
    "    \n",
    "    current_dataset_variety = root.split(\"\\\\\")[len(root.split(\"\\\\\"))-1]\n",
    "    input_file_full_path = os.path.join(root, file)\n",
    "    \n",
    "    !python MathFeature_Latest/methods/EntropyClass_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_Entropy-shannon.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -e Shannon -k {kmer}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tsallis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uses kmer, and tsallis entropic parameter\n",
    "\n",
    "for (root, file) in preprocessed_files_list:\n",
    "    \n",
    "    current_dataset_variety = root.split(\"\\\\\")[len(root.split(\"\\\\\"))-1]\n",
    "    input_file_full_path = os.path.join(root, file)\n",
    "    \n",
    "    !python MathFeature_Latest/methods/TsallisEntropy_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_Entropy-tsallis.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -q {tep} -k {kmer}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uses pattern (kmer) and threshold\n",
    "\n",
    "for (root, file) in preprocessed_files_list:\n",
    "    \n",
    "    current_dataset_variety = root.split(\"\\\\\")[len(root.split(\"\\\\\"))-1]\n",
    "    input_file_full_path = os.path.join(root, file)\n",
    "    \n",
    "    !python MathFeature_Latest/methods/ComplexNetworksClass_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_Complex-Network.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -k {kmer} -t {th}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 2 - no threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uses pattern (kmer)\n",
    "\n",
    "for (root, file) in preprocessed_files_list:\n",
    "    \n",
    "    current_dataset_variety = root.split(\"\\\\\")[len(root.split(\"\\\\\"))-1]\n",
    "    input_file_full_path = os.path.join(root, file)\n",
    "    \n",
    "    !python MathFeature_Latest/methods/ComplexNetworksClass-v2_Mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_Complex-Network-v2.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -k {kmer}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizable k-mer, NAC, DNC, TNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uses kmer, sliding window, and window step\n",
    "\n",
    "for (root, file) in preprocessed_files_list:\n",
    "    \n",
    "    current_dataset_variety = root.split(\"\\\\\")[len(root.split(\"\\\\\"))-1]\n",
    "    input_file_full_path = os.path.join(root, file)\n",
    "    \n",
    "    !python MathFeature_Latest/methods/ExtractionTechniques_mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_NAC.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -seq 2 -t NAC\n",
    "    !python MathFeature_Latest/methods/ExtractionTechniques_mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_DNC.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -seq 2 -t DNC\n",
    "    !python MathFeature_Latest/methods/ExtractionTechniques_mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_TNC.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -seq 2 -t TNC\n",
    "    !python MathFeature_Latest/methods/ExtractionTechniques_mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_kmer.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -seq 2 -t kmer -k {kmer}\n",
    "    !python MathFeature_Latest/methods/ExtractionTechniques_mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_rckmer.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -seq 2 -t rckmer -k {kmer}\n",
    "    !python MathFeature_Latest/methods/ExtractionTechniques_mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_kstep.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -seq 2 -t kstep -k {kmer} -w {sw} -s {ws}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accumulated Nucleotide Frequency (ANF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (root, file) in preprocessed_files_list:\n",
    "    \n",
    "    current_dataset_variety = root.split(\"\\\\\")[len(root.split(\"\\\\\"))-1]\n",
    "    input_file_full_path = os.path.join(root, file)\n",
    "    \n",
    "    !python MathFeature_Latest/methods/AccumulatedNucleotideFrequency_mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_ANF.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -r 1\n",
    "    !python MathFeature_Latest/methods/AccumulatedNucleotideFrequency_mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_ANFF.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -r 2\n",
    "    \n",
    "#     command = \"python MathFeature_Latest/methods/AccumulatedNucleotideFrequency_mod.py -i {} -l {} -o {} -r {}\".format(input_file_full_path, current_dataset_variety, \"_ANF.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\"), 1)\n",
    "#     os.system(command)\n",
    "    \n",
    "#     command = \"python MathFeature_Latest/methods/AccumulatedNucleotideFrequency_mod.py -i {} -l {} -o {} -r {}\".format(input_file_full_path, current_dataset_variety, \"_ANFF.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\"), 2)\n",
    "#     os.system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Reading Frame (ORF) descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (root, file) in preprocessed_files_list:\n",
    "    \n",
    "    current_dataset_variety = root.split(\"\\\\\")[len(root.split(\"\\\\\"))-1]\n",
    "    input_file_full_path = os.path.join(root, file)\n",
    "    \n",
    "    !python MathFeature_Latest/methods/CodingClass_mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_ORF.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fickett score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (root, file) in preprocessed_files_list:\n",
    "    \n",
    "    current_dataset_variety = root.split(\"\\\\\")[len(root.split(\"\\\\\"))-1]\n",
    "    input_file_full_path = os.path.join(root, file)\n",
    "    \n",
    "    !python MathFeature_Latest/methods/FickettScore_mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_Fickett.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -seq 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo k-tuple nucleotide composition - PseKNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (root, file) in preprocessed_files_list:\n",
    "    \n",
    "    current_dataset_variety = root.split(\"\\\\\")[len(root.split(\"\\\\\"))-1]\n",
    "    input_file_full_path = os.path.join(root, file)\n",
    "    \n",
    "    !python MathFeature_Latest/methods/PseKNC_mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_PseKNC1-DN.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -x MathFeature_Latest/files/propNames-RNA-k2.txt -xp MathFeature_Latest/files/propValues-RNA-k2.txt -seq 2 -t 1 -k 2 -j 1 -w 1.0 -s 2\n",
    "    !python MathFeature_Latest/methods/PseKNC_mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_PseKNC2-DN.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -x MathFeature_Latest/files/propNames-RNA-k2.txt -xp MathFeature_Latest/files/propValues-RNA-k2.txt -seq 2 -t 2 -k 2 -j 1 -w 1.0 -s 2\n",
    "    \n",
    "    !python MathFeature_Latest/methods/PseKNC_mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_PseKNC1-TN.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -x MathFeature_Latest/files/propNames-RNA-k2.txt -xp MathFeature_Latest/files/propValues-RNA-k2.txt -seq 2 -t 1 -k 3 -j 1 -w 1.0 -s 2\n",
    "    !python MathFeature_Latest/methods/PseKNC_mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_PseKNC2-TN.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -x MathFeature_Latest/files/propNames-RNA-k2.txt -xp MathFeature_Latest/files/propValues-RNA-k2.txt -seq 2 -t 2 -k 3 -j 1 -w 1.0 -s 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xmer k-Spaced Ymer Composition Frequency - kGap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (root, file) in preprocessed_files_list:\n",
    "    \n",
    "    current_dataset_variety = root.split(\"\\\\\")[len(root.split(\"\\\\\"))-1]\n",
    "    input_file_full_path = os.path.join(root, file)\n",
    "    \n",
    "    !python MathFeature_Latest/methods/Kgap_mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_kgap.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -k 1 -bef 1 -aft 1 -seq 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (root, file) in preprocessed_files_list:\n",
    "    \n",
    "    current_dataset_variety = root.split(\"\\\\\")[len(root.split(\"\\\\\"))-1]\n",
    "    input_file_full_path = os.path.join(root, file)\n",
    "    \n",
    "    !python MathFeature_Latest/methods/Kgap_mod.py -i {input_file_full_path} -l {current_dataset_variety} -o {\"_kgap2.\".join(input_file_full_path.split(\".\")).replace(\".txt\", \".csv\")} -k 2 -bef 2 -aft 2 -seq 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join ALL embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_file_types = [\"HS_990\", \"MM_944\", \"SS_628\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_list_file = []\n",
    "reject_list_encoding = ['NM-complex', 'Complex-Network']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_parent in parent_file_types:\n",
    "    \n",
    "    df_all = None\n",
    "    \n",
    "    for root, dirs, files in os.walk(out_path_datasets):\n",
    "        for file in files:\n",
    "\n",
    "            if (os.path.splitext(file)[-1] == '.csv') and (file not in reject_list_file):\n",
    "\n",
    "                current_dataset_variety = \"_\".join(file.split(\".\")[0].split(\"_\")[0:(len(file.split(\".\")[0].split(\"_\")) - 1)])\n",
    "                encoding_type = file.split(\".\")[0].split(\"_\")[-1]\n",
    "\n",
    "                if (current_dataset_variety == file_parent) and (encoding_type not in reject_list_encoding):\n",
    "                    \n",
    "                    print('Parent:', file_parent)\n",
    "                    print('File:', file)\n",
    "                    print('Vareity:',current_dataset_variety)\n",
    "                    print('Encoding:', encoding_type)\n",
    "                    print()\n",
    "\n",
    "                    ##################################################################################\n",
    "                    ##### read the current file\n",
    "                    ##################################################################################\n",
    "\n",
    "                    input_file_full_path = os.path.join(root, file)\n",
    "\n",
    "                    ## check if input file has header\n",
    "                    file_obj = open(input_file_full_path, \"r\")\n",
    "                    first_line = file_obj.readline()\n",
    "                    file_obj.close()\n",
    "                    file_has_header = None\n",
    "                    if first_line.split(\",\")[0] == \"nameseq\" or first_line.replace(\"\\n\", \"\").split(\",\")[-1] == \"label\":\n",
    "                        file_has_header = 0\n",
    "\n",
    "                    sequences_df = pd.read_csv(input_file_full_path, header = file_has_header)\n",
    "                    \n",
    "                    # fixing column headers\n",
    "                    col_names = [encoding_type + '_'+ str(val) for val in list(sequences_df.columns)]\n",
    "                    col_names[0] = 'nameseq'\n",
    "                    col_names[-1] = 'label'\n",
    "                    sequences_df.columns = col_names\n",
    "                    \n",
    "                    sequences_df = sequences_df.drop('label', axis = 1)\n",
    "                    \n",
    "                    # joining all data\n",
    "                    \n",
    "                    if type(df_all) != pd.DataFrame:\n",
    "                        df_all = sequences_df\n",
    "                        \n",
    "                    else:\n",
    "                        df_all = pd.merge(\n",
    "                            df_all,\n",
    "                            sequences_df,\n",
    "                            how=\"inner\",\n",
    "                            on='nameseq',\n",
    "                            validate='1:1',\n",
    "                        )\n",
    "    \n",
    "    out_path = os.path.join(output_data_folder, output_dataset+'_ALL')\n",
    "    out_file = file_parent+'_ALL.csv'\n",
    "    \n",
    "    if(not os.path.isdir(out_path)):\n",
    "            os.makedirs(out_path)\n",
    "    \n",
    "    if type(df_all) == pd.DataFrame:\n",
    "        df_all.to_csv(os.path.join(out_path, out_file), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Define all parameters for model tuning\n",
    "##################################################################################\n",
    "\n",
    "n_fold = 10\n",
    "expName = \"PSI_Site_DLNN_CORENup_RNAfold\"\n",
    "outPath = \"Results\"\n",
    "foldName = \"folds.pickle\"\n",
    "\n",
    "# modelNames = [\"DLNN_3\", \"DLNN_5\"]\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "shuffle = True\n",
    "seed = 22\n",
    "\n",
    "input_data_folder = \"Data\\\\Aziz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from Bio import SeqIO\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# print(tf.test.is_gpu_available(cuda_only=True))\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define all CUSTOM functions\n",
    "##################################################################################\n",
    "\n",
    "def one_hot_encode_dna(sequence):\n",
    "    seq_encoded = np.zeros((len(sequence),4))\n",
    "    dict_nuc = {\n",
    "        \"A\": 0,\n",
    "        \"C\": 1,\n",
    "        \"G\": 2,\n",
    "        \"T\": 3\n",
    "    }\n",
    "    i = 0\n",
    "    for single_character in sequence:\n",
    "        if(single_character.upper() in dict_nuc.keys()):\n",
    "            seq_encoded[i][dict_nuc[single_character.upper()]] = 1\n",
    "            i = i+1\n",
    "        else:\n",
    "            raise ValueError('Incorrect character in DNA sequence: '+sequence)\n",
    "    return seq_encoded\n",
    "\n",
    "def one_hot_encode_rna(sequence):\n",
    "    seq_encoded = np.zeros((len(sequence),4))\n",
    "    dict_nuc = {\n",
    "        \"A\": 0,\n",
    "        \"C\": 1,\n",
    "        \"G\": 2,\n",
    "        \"U\": 3\n",
    "    }\n",
    "    i = 0\n",
    "    for single_character in sequence:\n",
    "        if(single_character.upper() in dict_nuc.keys()):\n",
    "            seq_encoded[i][dict_nuc[single_character.upper()]] = 1\n",
    "            i = i+1\n",
    "        else:\n",
    "            raise ValueError('Incorrect character in RNA sequence: '+sequence)\n",
    "    return seq_encoded\n",
    "\n",
    "def one_hot_encode_rnafold(sequence):\n",
    "    seq_encoded = np.zeros((len(sequence),3))\n",
    "    dict_fold = {\n",
    "        \"(\": 0,\n",
    "        \")\": 1,\n",
    "        \".\": 2\n",
    "    }\n",
    "    i = 0\n",
    "    for single_character in sequence:\n",
    "        if(single_character in dict_fold.keys()):\n",
    "            seq_encoded[i][dict_fold[single_character]] = 1\n",
    "            i = i+1\n",
    "        else:\n",
    "            raise ValueError('Incorrect character in RNAfold: '+sequence)\n",
    "    return seq_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### define evaluator functions\n",
    "##################################################################################\n",
    "\n",
    "## Build the K-fold from dataset\n",
    "def build_kfold(features, labels, k=10, shuffle=False, seed=None):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "    kfoldList = []\n",
    "    for train_index, test_index in skf.split(features, labels):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        kfoldList.append({\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\":y_train,\n",
    "            \"y_test\":y_test\n",
    "        })\n",
    "    return kfoldList\n",
    "\n",
    "def build_kfold_multifeature(features_1, features_2, labels, k=10, shuffle=False, seed=None):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=seed)\n",
    "    kfoldList = []\n",
    "    for train_index, test_index in skf.split(features_1, labels):\n",
    "        X1_train, X1_test = features_1[train_index], features_1[test_index]\n",
    "        X2_train, X2_test = features_2[train_index], features_2[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        kfoldList.append({\n",
    "            \"X1_train\": X1_train,\n",
    "            \"X1_test\": X1_test,\n",
    "            \"X2_train\": X2_train,\n",
    "            \"X2_test\": X2_test,\n",
    "            \"y_train\":y_train,\n",
    "            \"y_test\":y_test\n",
    "        })\n",
    "    return kfoldList\n",
    "\n",
    "def pred2label(y_pred):\n",
    "    y_pred = np.round(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Function to customize the DLNN architecture with parameters\n",
    "##################################################################################\n",
    "\n",
    "def DLNN_CORENup_RNAFold(input_seq_len = 21,\n",
    "                   conv_filters_per_layer_1 = 50, kernel_length_1 = 5, conv_strides_1 = 1, ## 1st Convolutional layer parameters\n",
    "                   max_pool_width_1 = 2, max_pool_stride_1 = 2, ## 1st Maxpool layer parameters\n",
    "                   lstm_decode_units = 75, ## LSTM layer parameters\n",
    "                   conv_filters_per_layer_2 = 50,  kernel_length_2 = 5, conv_strides_2 = 1, ## 2nd Convolutional layer parameters\n",
    "                   max_pool_width_2 = 2, max_pool_stride_2 = 2, ## 2nd Maxpool layer parameters\n",
    "                   dense_decode_units = 400, ## Dense layer parameters\n",
    "                   prob = 0.2, learn_rate = 0.001, loss = 'binary_crossentropy', metrics = 'accuracy'):\n",
    "    \n",
    "    beta = 0.001\n",
    "    \n",
    "    input_shape_seq = (input_seq_len, 4)\n",
    "    input_shape_fold = (input_seq_len, 3)\n",
    "    \n",
    "    ######################################################################################################\n",
    "    ########  SEQUENCE  ##################################################################################\n",
    "    ######################################################################################################\n",
    "    \n",
    "    input1 = tf.keras.layers.Input(shape=input_shape_seq)\n",
    "\n",
    "    x1 = tf.keras.layers.Conv1D(conv_filters_per_layer_1, kernel_length_1,\n",
    "                                strides = conv_strides_1, kernel_regularizer = tf.keras.regularizers.l2(beta)\n",
    "                               )(input1)\n",
    "    x1 = tf.keras.layers.Activation('relu')(x1)\n",
    "    x1 = tf.keras.layers.MaxPool1D(pool_size = max_pool_width_1, strides = max_pool_stride_1)(x1)\n",
    "    x1 = tf.keras.layers.Dropout(prob)(x1)\n",
    "\n",
    "    ## LSTM Path\n",
    "\n",
    "    x2 = tf.keras.layers.LSTM(lstm_decode_units, return_sequences = True, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta))(x1)\n",
    "    x2 = tf.keras.layers.Dropout(prob)(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "\n",
    "    ## Conv Path\n",
    "\n",
    "    x3 = tf.keras.layers.Conv1D(conv_filters_per_layer_2, kernel_length_2, strides = conv_strides_2, \n",
    "                                kernel_regularizer = tf.keras.regularizers.l2(beta), padding = 'same')(x1)\n",
    "    x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "    x3 = tf.keras.layers.MaxPooling1D(pool_size = max_pool_width_2, strides = max_pool_stride_2)(x3)\n",
    "    x3 = tf.keras.layers.Dropout(prob)(x3)\n",
    "    \n",
    "    x3 = tf.keras.layers.Flatten()(x3)\n",
    "    \n",
    "    x4 = tf.keras.layers.Concatenate(1)([x2,x3])\n",
    "    \n",
    "    ######################################################################################################\n",
    "    ########  RNA Fold  ##################################################################################\n",
    "    ######################################################################################################\n",
    "    \n",
    "    input2 = tf.keras.layers.Input(shape=input_shape_fold)\n",
    "    \n",
    "    f1 = tf.keras.layers.Conv1D(conv_filters_per_layer_1, kernel_length_1,\n",
    "                                strides = conv_strides_1, kernel_regularizer = tf.keras.regularizers.l2(beta)\n",
    "                               )(input2)\n",
    "    f1 = tf.keras.layers.Activation('relu')(f1)\n",
    "    f1 = tf.keras.layers.MaxPool1D(pool_size = max_pool_width_1, strides = max_pool_stride_1)(f1)\n",
    "    f1 = tf.keras.layers.Dropout(prob)(f1)\n",
    "\n",
    "    ## LSTM Path\n",
    "\n",
    "    f2 = tf.keras.layers.LSTM(lstm_decode_units, return_sequences = True, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta))(f1)\n",
    "    f2 = tf.keras.layers.Dropout(prob)(f2)\n",
    "    \n",
    "    f2 = tf.keras.layers.Flatten()(f2)\n",
    "\n",
    "    ## Conv Path\n",
    "\n",
    "    f3 = tf.keras.layers.Conv1D(conv_filters_per_layer_2, kernel_length_2, strides = conv_strides_2, \n",
    "                                kernel_regularizer = tf.keras.regularizers.l2(beta)\n",
    "                               )(f1)\n",
    "    f3 = tf.keras.layers.Activation('relu')(f3)\n",
    "    f3 = tf.keras.layers.MaxPooling1D(pool_size = max_pool_width_2, strides = max_pool_stride_2)(f3)\n",
    "    f3 = tf.keras.layers.Dropout(prob)(f3)\n",
    "    \n",
    "    f3 = tf.keras.layers.Flatten()(f3)\n",
    "    \n",
    "    f4 = tf.keras.layers.Concatenate(1)([f2,f3])\n",
    "    \n",
    "    ######################################################################################################\n",
    "    ########  Classifier  ################################################################################\n",
    "    ######################################################################################################\n",
    "\n",
    "    ## Fully connected Layers\n",
    "\n",
    "    y = tf.keras.layers.Concatenate()([x4,f4])\n",
    "    \n",
    "    y = tf.keras.layers.Dense(dense_decode_units, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                              activation = 'relu')(y)\n",
    "    \n",
    "    y = tf.keras.layers.Dropout(prob)(y)\n",
    "    \n",
    "    y = tf.keras.layers.Dense(1, \n",
    "                              kernel_regularizer = tf.keras.regularizers.l2(beta), \n",
    "                              activation = 'sigmoid')(y)\n",
    "\n",
    "    ## Generate Model from input and output\n",
    "    model = tf.keras.models.Model(inputs=[input1, input2], outputs=y)\n",
    "    \n",
    "    optimizer_function = tf.keras.optimizers.Adagrad(learning_rate=learn_rate)\n",
    "    \n",
    "    ## Compile model\n",
    "    if(metrics != None):\n",
    "        model.compile(optimizer = optimizer_function, loss = loss, metrics = metrics)\n",
    "    else:\n",
    "        model.compile(optimizer = optimizer_function, loss = loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 21, 4)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 21, 3)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 21, 50)       1050        input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 21, 50)       800         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 21, 50)       0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 21, 50)       0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 10, 50)       0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 10, 50)       0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 10, 50)       0           max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 10, 50)       0           max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 10, 50)       12550       dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 10, 50)       12550       dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 10, 50)       0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 10, 50)       0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 10, 75)       37800       dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 5, 50)        0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, 10, 75)       37800       dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 5, 50)        0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 10, 75)       0           lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 5, 50)        0           max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 10, 75)       0           lstm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 5, 50)        0           max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 750)          0           dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 250)          0           dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 750)          0           dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 250)          0           dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 1000)         0           flatten_12[0][0]                 \n",
      "                                                                 flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 1000)         0           flatten_14[0][0]                 \n",
      "                                                                 flatten_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 2000)         0           concatenate_9[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 400)          800400      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 400)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            401         dropout_27[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 903,351\n",
      "Trainable params: 903,351\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DLNN_CORENup_RNAFold().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "File: Data\\Aziz\\HS_990.csv\n",
      "Positive: 495\n",
      "Negative: 495\n",
      "\n",
      "Train/Test model HS_990 on Fold #0.\n",
      "Epoch 1/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.6218 - accuracy: 0.6124\n",
      "Epoch 00001: val_loss improved from inf to 1.87513, saving model to Results\\PSI_Site_DLNN_CORENup_RNAfold\\HS_990\\10fold\\models\\HS_990_bestModel-fold0.hdf5\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 1.6218 - accuracy: 0.6124 - val_loss: 1.8751 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "44/45 [============================>.] - ETA: 0s - loss: 1.6063 - accuracy: 0.6264\n",
      "Epoch 00002: val_loss improved from 1.87513 to 1.78243, saving model to Results\\PSI_Site_DLNN_CORENup_RNAfold\\HS_990\\10fold\\models\\HS_990_bestModel-fold0.hdf5\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 1.6070 - accuracy: 0.6250 - val_loss: 1.7824 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "41/45 [==========================>...] - ETA: 0s - loss: 1.5966 - accuracy: 0.6296\n",
      "Epoch 00003: val_loss did not improve from 1.78243\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5982 - accuracy: 0.6250 - val_loss: 1.8286 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "41/45 [==========================>...] - ETA: 0s - loss: 1.5881 - accuracy: 0.6311\n",
      "Epoch 00004: val_loss did not improve from 1.78243\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5906 - accuracy: 0.6250 - val_loss: 1.8269 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "41/45 [==========================>...] - ETA: 0s - loss: 1.5832 - accuracy: 0.6296\n",
      "Epoch 00005: val_loss did not improve from 1.78243\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5840 - accuracy: 0.6250 - val_loss: 1.7855 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5799 - accuracy: 0.6250\n",
      "Epoch 00006: val_loss did not improve from 1.78243\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5799 - accuracy: 0.6250 - val_loss: 1.8309 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "44/45 [============================>.] - ETA: 0s - loss: 1.5697 - accuracy: 0.6264\n",
      "Epoch 00007: val_loss did not improve from 1.78243\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 1.5704 - accuracy: 0.6250 - val_loss: 1.8911 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "42/45 [===========================>..] - ETA: 0s - loss: 1.5656 - accuracy: 0.6250\n",
      "Epoch 00008: val_loss did not improve from 1.78243\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.5664 - accuracy: 0.6250 - val_loss: 1.8857 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "41/45 [==========================>...] - ETA: 0s - loss: 1.5579 - accuracy: 0.6265\n",
      "Epoch 00009: val_loss did not improve from 1.78243\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5592 - accuracy: 0.6250 - val_loss: 1.9507 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "44/45 [============================>.] - ETA: 0s - loss: 1.5528 - accuracy: 0.6250\n",
      "Epoch 00010: val_loss did not improve from 1.78243\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 1.5532 - accuracy: 0.6250 - val_loss: 1.8460 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5455 - accuracy: 0.6236\n",
      "Epoch 00011: val_loss did not improve from 1.78243\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 1.5455 - accuracy: 0.6236 - val_loss: 1.8149 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "41/45 [==========================>...] - ETA: 0s - loss: 1.5400 - accuracy: 0.6265\n",
      "Epoch 00012: val_loss did not improve from 1.78243\n",
      "Restoring model weights from the end of the best epoch.\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 1.5403 - accuracy: 0.6250 - val_loss: 1.8824 - val_accuracy: 0.0000e+00\n",
      "Epoch 00012: early stopping\n",
      "\n",
      "Train/Test model HS_990 on Fold #1.\n",
      "Epoch 1/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.6147 - accuracy: 0.6152\n",
      "Epoch 00001: val_loss improved from inf to 1.88755, saving model to Results\\PSI_Site_DLNN_CORENup_RNAfold\\HS_990\\10fold\\models\\HS_990_bestModel-fold1.hdf5\n",
      "45/45 [==============================] - 1s 27ms/step - loss: 1.6147 - accuracy: 0.6152 - val_loss: 1.8876 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.6068 - accuracy: 0.6250\n",
      "Epoch 00002: val_loss did not improve from 1.88755\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.6068 - accuracy: 0.6250 - val_loss: 1.8981 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "41/45 [==========================>...] - ETA: 0s - loss: 1.5973 - accuracy: 0.6265\n",
      "Epoch 00003: val_loss did not improve from 1.88755\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 1.5978 - accuracy: 0.6250 - val_loss: 1.8936 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "42/45 [===========================>..] - ETA: 0s - loss: 1.5876 - accuracy: 0.6205\n",
      "Epoch 00004: val_loss did not improve from 1.88755\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5860 - accuracy: 0.6250 - val_loss: 1.9513 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "43/45 [===========================>..] - ETA: 0s - loss: 1.5832 - accuracy: 0.6279\n",
      "Epoch 00005: val_loss improved from 1.88755 to 1.80858, saving model to Results\\PSI_Site_DLNN_CORENup_RNAfold\\HS_990\\10fold\\models\\HS_990_bestModel-fold1.hdf5\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 1.5843 - accuracy: 0.6250 - val_loss: 1.8086 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "41/45 [==========================>...] - ETA: 0s - loss: 1.5761 - accuracy: 0.6235\n",
      "Epoch 00006: val_loss did not improve from 1.80858\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 1.5763 - accuracy: 0.6250 - val_loss: 1.9502 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "42/45 [===========================>..] - ETA: 0s - loss: 1.5699 - accuracy: 0.6250\n",
      "Epoch 00007: val_loss did not improve from 1.80858\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5709 - accuracy: 0.6250 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "41/45 [==========================>...] - ETA: 0s - loss: 1.5656 - accuracy: 0.6220\n",
      "Epoch 00008: val_loss did not improve from 1.80858\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5635 - accuracy: 0.6250 - val_loss: 1.9044 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "44/45 [============================>.] - ETA: 0s - loss: 1.5547 - accuracy: 0.6264\n",
      "Epoch 00009: val_loss did not improve from 1.80858\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 1.5530 - accuracy: 0.6278 - val_loss: 1.9336 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "41/45 [==========================>...] - ETA: 0s - loss: 1.5494 - accuracy: 0.6250\n",
      "Epoch 00010: val_loss improved from 1.80858 to 1.79636, saving model to Results\\PSI_Site_DLNN_CORENup_RNAfold\\HS_990\\10fold\\models\\HS_990_bestModel-fold1.hdf5\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 1.5499 - accuracy: 0.6250 - val_loss: 1.7964 - val_accuracy: 0.0168\n",
      "Epoch 11/100\n",
      "42/45 [===========================>..] - ETA: 0s - loss: 1.5364 - accuracy: 0.6324\n",
      "Epoch 00011: val_loss did not improve from 1.79636\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 1.5369 - accuracy: 0.6320 - val_loss: 1.8989 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5330 - accuracy: 0.6362\n",
      "Epoch 00012: val_loss did not improve from 1.79636\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 1.5330 - accuracy: 0.6362 - val_loss: 1.9270 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "42/45 [===========================>..] - ETA: 0s - loss: 1.5272 - accuracy: 0.6354\n",
      "Epoch 00013: val_loss did not improve from 1.79636\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5277 - accuracy: 0.6306 - val_loss: 1.8463 - val_accuracy: 0.0223\n",
      "Epoch 14/100\n",
      "42/45 [===========================>..] - ETA: 0s - loss: 1.5101 - accuracy: 0.6429\n",
      "Epoch 00014: val_loss improved from 1.79636 to 1.71453, saving model to Results\\PSI_Site_DLNN_CORENup_RNAfold\\HS_990\\10fold\\models\\HS_990_bestModel-fold1.hdf5\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 1.5165 - accuracy: 0.6348 - val_loss: 1.7145 - val_accuracy: 0.2011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "41/45 [==========================>...] - ETA: 0s - loss: 1.5164 - accuracy: 0.6357\n",
      "Epoch 00015: val_loss did not improve from 1.71453\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 1.5090 - accuracy: 0.6433 - val_loss: 1.9635 - val_accuracy: 0.0056\n",
      "Epoch 16/100\n",
      "44/45 [============================>.] - ETA: 0s - loss: 1.5049 - accuracy: 0.6449\n",
      "Epoch 00016: val_loss did not improve from 1.71453\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5045 - accuracy: 0.6461 - val_loss: 1.8748 - val_accuracy: 0.0391\n",
      "Epoch 17/100\n",
      "41/45 [==========================>...] - ETA: 0s - loss: 1.4969 - accuracy: 0.6555\n",
      "Epoch 00017: val_loss did not improve from 1.71453\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.4981 - accuracy: 0.6531 - val_loss: 1.8186 - val_accuracy: 0.0670\n",
      "Epoch 18/100\n",
      "43/45 [===========================>..] - ETA: 0s - loss: 1.4897 - accuracy: 0.6439\n",
      "Epoch 00018: val_loss did not improve from 1.71453\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.4886 - accuracy: 0.6433 - val_loss: 1.8352 - val_accuracy: 0.0782\n",
      "Epoch 19/100\n",
      "43/45 [===========================>..] - ETA: 0s - loss: 1.4819 - accuracy: 0.6483\n",
      "Epoch 00019: val_loss did not improve from 1.71453\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.4824 - accuracy: 0.6461 - val_loss: 1.7440 - val_accuracy: 0.2123\n",
      "Epoch 20/100\n",
      "44/45 [============================>.] - ETA: 0s - loss: 1.4781 - accuracy: 0.6634\n",
      "Epoch 00020: val_loss did not improve from 1.71453\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.4782 - accuracy: 0.6629 - val_loss: 1.7726 - val_accuracy: 0.1508\n",
      "Epoch 21/100\n",
      "42/45 [===========================>..] - ETA: 0s - loss: 1.4782 - accuracy: 0.6458\n",
      "Epoch 00021: val_loss did not improve from 1.71453\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.4728 - accuracy: 0.6503 - val_loss: 1.9245 - val_accuracy: 0.0615\n",
      "Epoch 22/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4619 - accuracy: 0.6573\n",
      "Epoch 00022: val_loss did not improve from 1.71453\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.4619 - accuracy: 0.6573 - val_loss: 1.9960 - val_accuracy: 0.0279\n",
      "Epoch 23/100\n",
      "41/45 [==========================>...] - ETA: 0s - loss: 1.4629 - accuracy: 0.6524\n",
      "Epoch 00023: val_loss did not improve from 1.71453\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.4563 - accuracy: 0.6601 - val_loss: 1.8998 - val_accuracy: 0.0782\n",
      "Epoch 24/100\n",
      "44/45 [============================>.] - ETA: 0s - loss: 1.4472 - accuracy: 0.6662\n",
      "Epoch 00024: val_loss did not improve from 1.71453\n",
      "Restoring model weights from the end of the best epoch.\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 1.4471 - accuracy: 0.6671 - val_loss: 1.8932 - val_accuracy: 0.0782\n",
      "Epoch 00024: early stopping\n",
      "\n",
      "Train/Test model HS_990 on Fold #2.\n",
      "Epoch 1/100\n",
      "42/45 [===========================>..] - ETA: 0s - loss: 1.6227 - accuracy: 0.6057\n",
      "Epoch 00001: val_loss improved from inf to 1.79101, saving model to Results\\PSI_Site_DLNN_CORENup_RNAfold\\HS_990\\10fold\\models\\HS_990_bestModel-fold2.hdf5\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 1.6230 - accuracy: 0.6039 - val_loss: 1.7910 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "42/45 [===========================>..] - ETA: 0s - loss: 1.6086 - accuracy: 0.6265\n",
      "Epoch 00002: val_loss did not improve from 1.79101\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.6089 - accuracy: 0.6250 - val_loss: 1.9137 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "42/45 [===========================>..] - ETA: 0s - loss: 1.5988 - accuracy: 0.6265\n",
      "Epoch 00003: val_loss did not improve from 1.79101\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5999 - accuracy: 0.6250 - val_loss: 1.8882 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5897 - accuracy: 0.6250\n",
      "Epoch 00004: val_loss did not improve from 1.79101\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 1.5897 - accuracy: 0.6250 - val_loss: 1.9500 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "44/45 [============================>.] - ETA: 0s - loss: 1.5852 - accuracy: 0.6222\n",
      "Epoch 00005: val_loss did not improve from 1.79101\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5834 - accuracy: 0.6250 - val_loss: 1.9801 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "42/45 [===========================>..] - ETA: 0s - loss: 1.5792 - accuracy: 0.6205\n",
      "Epoch 00006: val_loss did not improve from 1.79101\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 1.5770 - accuracy: 0.6250 - val_loss: 1.9355 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "44/45 [============================>.] - ETA: 0s - loss: 1.5673 - accuracy: 0.6236\n",
      "Epoch 00007: val_loss did not improve from 1.79101\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.5664 - accuracy: 0.6264 - val_loss: 1.9054 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5601 - accuracy: 0.6292\n",
      "Epoch 00008: val_loss did not improve from 1.79101\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5601 - accuracy: 0.6292 - val_loss: 1.9501 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "41/45 [==========================>...] - ETA: 0s - loss: 1.5551 - accuracy: 0.6235\n",
      "Epoch 00009: val_loss did not improve from 1.79101\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.5582 - accuracy: 0.6208 - val_loss: 1.9402 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "42/45 [===========================>..] - ETA: 0s - loss: 1.5472 - accuracy: 0.6295\n",
      "Epoch 00010: val_loss did not improve from 1.79101\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5481 - accuracy: 0.6278 - val_loss: 1.9104 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "43/45 [===========================>..] - ETA: 0s - loss: 1.5391 - accuracy: 0.6279\n",
      "Epoch 00011: val_loss did not improve from 1.79101\n",
      "Restoring model weights from the end of the best epoch.\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5373 - accuracy: 0.6320 - val_loss: 1.9747 - val_accuracy: 0.0000e+00\n",
      "Epoch 00011: early stopping\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-83fb1f3a0e5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[1;31m##################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"X1_train\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"X2_train\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m             \u001b[0mlabel_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred2label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[1;31m# Compute precision, recall, sensitivity, specifity, mcc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m     87\u001b[0m           method.__name__))\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1266\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1268\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1269\u001b[0m             \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1270\u001b[0m             \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    625\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 506\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2445\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2446\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2447\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2777\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2779\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2667\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2669\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    962\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m                     \u001b[0muser_requested\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    965\u001b[0m                 ))\n\u001b[0;32m    966\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFunctionScope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict_function'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fscope'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_requested\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduce_per_replica\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'concat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    416\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_in_whitelist_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Whitelisted %s: from cache'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    949\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m    950\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m--> 951\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m   \u001b[1;31m# TODO(b/151224785): Remove deprecated alias.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2288\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2289\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2290\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2292\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2647\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2648\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[1;32m-> 2649\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2651\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperimental_hints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    416\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_in_whitelist_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Whitelisted %s: from cache'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munpack_x_y_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mmake_predict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    925\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 927\u001b[1;33m                   \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    717\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m    718\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m           \u001b[1;31m# Compute outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m           \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m           \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    925\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 927\u001b[1;33m                   \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m   1185\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m         (last_output, outputs, new_h, new_c,\n\u001b[1;32m-> 1187\u001b[1;33m          runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n\u001b[0m\u001b[0;32m   1188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m       \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mlstm_with_backend_selection\u001b[1;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, activation, recurrent_activation, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[0;32m   1564\u001b[0m   \u001b[1;31m# grappler will kick in during session execution to optimize the graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m   last_output, outputs, new_h, new_c, runtime = defun_standard_lstm(\n\u001b[1;32m-> 1566\u001b[1;33m       **params)\n\u001b[0m\u001b[0;32m   1567\u001b[0m   \u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefun_gpu_lstm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2417\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2419\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2420\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2777\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2779\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2667\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2669\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mstandard_lstm\u001b[1;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, activation, recurrent_activation, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       input_length=(sequence_lengths\n\u001b[0;32m   1319\u001b[0m                     if sequence_lengths is not None else timesteps),\n\u001b[1;32m-> 1320\u001b[1;33m       zero_output_for_mask=zero_output_for_mask)\n\u001b[0m\u001b[0;32m   1321\u001b[0m   return (last_output, outputs, new_states[0], new_states[1],\n\u001b[0;32m   1322\u001b[0m           _runtime(_RUNTIME_CPU))\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mrnn\u001b[1;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[0;32m   4090\u001b[0m     \u001b[1;31m# the value is discarded.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4091\u001b[0m     output_time_zero, _ = step_function(\n\u001b[1;32m-> 4092\u001b[1;33m         input_time_zero, tuple(initial_states) + tuple(constants))\n\u001b[0m\u001b[0;32m   4093\u001b[0m     output_ta = tuple(\n\u001b[0;32m   4094\u001b[0m         tensor_array_ops.TensorArray(\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(cell_inputs, cell_states)\u001b[0m\n\u001b[0;32m   1296\u001b[0m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m     \u001b[0mz\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_tm1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecurrent_kernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1298\u001b[1;33m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m     \u001b[0mz0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mbias_add\u001b[1;34m(x, bias, data_format)\u001b[0m\n\u001b[0;32m   5623\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_first'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5624\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NCHW'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5625\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NHWC'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5626\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5627\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_first'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m   2776\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2777\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2778\u001b[1;33m       \u001b[0mbias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"bias\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2780\u001b[0m     \u001b[1;31m# TODO(duncanriach): Implement deterministic functionality at CUDA kernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1341\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_dense_var_to_tensor\u001b[1;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m   1823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1824\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_dense_var_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1825\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_var_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_dense_var_to_tensor\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1240\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1242\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__iadd__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munused_other\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mvalue\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    548\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_existing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_as_graph_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m           \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[1;34m()\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m       result = gen_resource_variable_ops.read_variable_op(self._handle,\n\u001b[1;32m--> 636\u001b[1;33m                                                           self._dtype)\n\u001b[0m\u001b[0;32m    637\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    481\u001b[0m   \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[1;32m--> 483\u001b[1;33m         \"ReadVariableOp\", resource=resource, dtype=dtype, name=name)\n\u001b[0m\u001b[0;32m    484\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    742\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0;32m    743\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[0;32m    745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m         compute_device)\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3326\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3327\u001b[0m           op_def=op_def)\n\u001b[1;32m-> 3328\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3329\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[1;34m(self, op, compute_device)\u001b[0m\n\u001b[0;32m   3401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3402\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3403\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_device_functions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3405\u001b[0m     \u001b[1;31m# Snapshot the colocation stack metadata before we might generate error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\base_tf_24\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_apply_device_functions\u001b[1;34m(self, op)\u001b[0m\n\u001b[0;32m   4287\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4288\u001b[0m     \u001b[0mprior_device_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4289\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mdevice_spec\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_device_function_stack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpeek_objs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4290\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mdevice_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_null_merge\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4291\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "##### For each input file, train model and generate different outputs in a structured folder\n",
    "##################################################################################\n",
    "\n",
    "## create the evaluation data structure for all iterations\n",
    "evaluations = {\n",
    "    \"Model\" : [],\n",
    "    \"Dataset\" : [],\n",
    "    \"Fold\" : [],\n",
    "    \"Train_Test\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"Precision\": [],\n",
    "    \"TPR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"TPR_FPR_Thresholds\": [],\n",
    "    \"AUC\": [],\n",
    "    \"Sensitivity\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"MCC\":[]\n",
    "}\n",
    "\n",
    "for root, dirs, files in os.walk(input_data_folder):\n",
    "    for file in files:\n",
    "        \n",
    "        input_data_file = os.path.join(root, file)\n",
    "        \n",
    "        current_dataset_variety = input_data_file.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "        csv_data = pd.read_csv(input_data_file)\n",
    "\n",
    "        ##################################################################################\n",
    "        ##### extract data from the current CSV file\n",
    "        ##################################################################################\n",
    "\n",
    "        csv_data[\"OHE_Sequence\"] = pd.Series([one_hot_encode_rna(val) for val in csv_data[\"Sequence\"]])\n",
    "        csv_data[\"OHE_RNAfold\"] = pd.Series([one_hot_encode_rnafold(val) for val in csv_data[\"RNAfold\"]])\n",
    "\n",
    "        df_positive = csv_data[csv_data['Number'].str.contains(\"P\")]\n",
    "        df_negative = csv_data[csv_data['Number'].str.contains(\"N\")]\n",
    "\n",
    "        positive_onehotencoded_List = (np.array(list(df_positive['OHE_Sequence'])), np.array(list(df_positive['OHE_RNAfold'])))\n",
    "        negative_onehotencoded_List = (np.array(list(df_negative['OHE_Sequence'])), np.array(list(df_negative['OHE_RNAfold'])))\n",
    "\n",
    "        print(\"\\n======================================================================\")\n",
    "        print(\"\\nFile:\", input_data_file)\n",
    "        print(\"Positive:\", len(positive_onehotencoded_List[0]))\n",
    "        print(\"Negative:\", len(negative_onehotencoded_List[0]))\n",
    "\n",
    "        ##################################################################################\n",
    "        ##### Generate Folds from dataset, and store to file\n",
    "        ##################################################################################\n",
    "\n",
    "        ## create the features and labels datasets for the training\n",
    "        input_seq_len = len(positive_onehotencoded_List[0][0])\n",
    "        input_size_1 = (len(positive_onehotencoded_List[0][0]), 4)\n",
    "        input_size_2 = (len(positive_onehotencoded_List[0][0]), 3)\n",
    "\n",
    "        labels = np.concatenate((np.ones((positive_onehotencoded_List[0].shape[0], 1), \n",
    "                                         dtype=np.float32), \n",
    "                                 np.zeros((negative_onehotencoded_List[0].shape[0], 1), \n",
    "                                          dtype=np.float32)), \n",
    "                                axis=0)\n",
    "        features_1 = np.concatenate((positive_onehotencoded_List[0], \n",
    "                                     negative_onehotencoded_List[0]), \n",
    "                                    axis=0)\n",
    "        features_2 = np.concatenate((positive_onehotencoded_List[1], \n",
    "                                     negative_onehotencoded_List[1]), \n",
    "                                    axis=0)\n",
    "\n",
    "        folds = build_kfold_multifeature(features_1, features_2, labels, \n",
    "                                         k=n_fold, shuffle=shuffle, seed=seed)\n",
    "\n",
    "        ## Write the k-fold dataset to file\n",
    "        foldPath = os.path.join(outPath, expName, current_dataset_variety, \"{}fold\".format(n_fold))\n",
    "        if(not os.path.isdir(foldPath)):\n",
    "            os.makedirs(foldPath)\n",
    "        pickle.dump(folds, open(os.path.join(foldPath, foldName), \"wb\"))\n",
    "\n",
    "        ## Create and set directory to save model\n",
    "        modelPath = os.path.join(outPath, expName, current_dataset_variety, \"{}fold\".format(n_fold), \"models\")\n",
    "        if(not os.path.isdir(modelPath)):\n",
    "            os.makedirs(modelPath)\n",
    "\n",
    "        ##################################################################################\n",
    "        ##### TRAIN and PREDICT for every Fold, using models\n",
    "        ##################################################################################\n",
    "\n",
    "        # fold counter\n",
    "        i = 0\n",
    "\n",
    "        for fold in folds:\n",
    "\n",
    "            print(\"\\nTrain/Test model \"+current_dataset_variety+\" on Fold #\"+str(i)+\".\")\n",
    "\n",
    "            model = DLNN_CORENup_RNAFold(input_seq_len = input_seq_len)\n",
    "\n",
    "            # Define the model callbacks for early stopping and saving the model. Then train model\n",
    "            modelCallbacks = [\n",
    "                tf.keras.callbacks.ModelCheckpoint(os.path.join(modelPath, \"{}_bestModel-fold{}.hdf5\".format(current_dataset_variety, i)),\n",
    "                                                   monitor = 'val_loss', verbose = 1, save_best_only = True, \n",
    "                                                   save_weights_only = False, mode = 'auto', save_freq = 'epoch'),\n",
    "            ]\n",
    "            \n",
    "            # train the model\n",
    "            model.fit(x = [fold[\"X1_train\"], fold[\"X2_train\"]], y = fold[\"y_train\"], \n",
    "                      batch_size = batch_size, epochs = epochs, verbose = 1, \n",
    "                      callbacks = modelCallbacks, validation_split=0.2)\n",
    "\n",
    "            ##################################################################################\n",
    "            ##### Prediction and metrics for TRAIN dataset\n",
    "            ##################################################################################\n",
    "\n",
    "            y_pred = model.predict([fold[\"X1_train\"], fold[\"X2_train\"]])\n",
    "            label_pred = pred2label(y_pred)\n",
    "            # Compute precision, recall, sensitivity, specifity, mcc\n",
    "            acc = accuracy_score(fold[\"y_train\"], label_pred)\n",
    "            prec = precision_score(fold[\"y_train\"],label_pred)\n",
    "\n",
    "            conf = confusion_matrix(fold[\"y_train\"], label_pred)\n",
    "            if(conf[0][0]+conf[1][0]):\n",
    "                sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "            else:\n",
    "                sens = 0.0\n",
    "            if(conf[1][1]+conf[0][1]):\n",
    "                spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "            else:\n",
    "                spec = 0.0\n",
    "            if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "                mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "            else:\n",
    "                mcc= 0.0\n",
    "            fpr, tpr, thresholds = roc_curve(fold[\"y_train\"], y_pred)\n",
    "            auc = roc_auc_score(fold[\"y_train\"], y_pred)\n",
    "\n",
    "            evaluations[\"Model\"].append(current_dataset_variety)\n",
    "            evaluations[\"Dataset\"].append(current_dataset_variety)\n",
    "            evaluations[\"Fold\"].append(i)\n",
    "            evaluations[\"Train_Test\"].append(\"Train\")\n",
    "            evaluations[\"Accuracy\"].append(acc)\n",
    "            evaluations[\"Precision\"].append(prec)\n",
    "            evaluations[\"TPR\"].append(tpr)\n",
    "            evaluations[\"FPR\"].append(fpr)\n",
    "            evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "            evaluations[\"AUC\"].append(auc)\n",
    "            evaluations[\"Sensitivity\"].append(sens)\n",
    "            evaluations[\"Specificity\"].append(spec)\n",
    "            evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "            ##################################################################################\n",
    "            ##### Prediction and metrics for TEST dataset\n",
    "            ##################################################################################\n",
    "\n",
    "            y_pred = model.predict([fold[\"X1_test\"], fold[\"X2_test\"]])\n",
    "            label_pred = pred2label(y_pred)\n",
    "            # Compute precision, recall, sensitivity, specifity, mcc\n",
    "            acc = accuracy_score(fold[\"y_test\"], label_pred)\n",
    "            prec = precision_score(fold[\"y_test\"],label_pred)\n",
    "\n",
    "            conf = confusion_matrix(fold[\"y_test\"], label_pred)\n",
    "            if(conf[0][0]+conf[1][0]):\n",
    "                sens = float(conf[0][0])/float(conf[0][0]+conf[1][0])\n",
    "            else:\n",
    "                sens = 0.0\n",
    "            if(conf[1][1]+conf[0][1]):\n",
    "                spec = float(conf[1][1])/float(conf[1][1]+conf[0][1])\n",
    "            else:\n",
    "                spec = 0.0\n",
    "            if((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0])):\n",
    "                mcc = (float(conf[0][0])*float(conf[1][1]) - float(conf[1][0])*float(conf[0][1]))/math.sqrt((conf[0][0]+conf[0][1])*(conf[0][0]+conf[1][0])*(conf[1][1]+conf[0][1])*(conf[1][1]+conf[1][0]))\n",
    "            else:\n",
    "                mcc= 0.0\n",
    "            fpr, tpr, thresholds = roc_curve(fold[\"y_test\"], y_pred)\n",
    "            auc = roc_auc_score(fold[\"y_test\"], y_pred)\n",
    "\n",
    "            evaluations[\"Model\"].append(current_dataset_variety)\n",
    "            evaluations[\"Dataset\"].append(current_dataset_variety)\n",
    "            evaluations[\"Fold\"].append(i)\n",
    "            evaluations[\"Train_Test\"].append(\"Test\")\n",
    "            evaluations[\"Accuracy\"].append(acc)\n",
    "            evaluations[\"Precision\"].append(prec)\n",
    "            evaluations[\"TPR\"].append(tpr)\n",
    "            evaluations[\"FPR\"].append(fpr)\n",
    "            evaluations[\"TPR_FPR_Thresholds\"].append(thresholds)\n",
    "            evaluations[\"AUC\"].append(auc)\n",
    "            evaluations[\"Sensitivity\"].append(sens)\n",
    "            evaluations[\"Specificity\"].append(spec)\n",
    "            evaluations[\"MCC\"].append(mcc)\n",
    "\n",
    "            i = i+1\n",
    "            del model\n",
    "            tf.keras.backend.clear_session()\n",
    "\n",
    "        ##################################################################################\n",
    "        ##### Dump evaluations to a file\n",
    "        ##################################################################################\n",
    "\n",
    "        evalPath = os.path.join(outPath, expName, \"_Evaluation_All_Datasets\")\n",
    "        if(not os.path.isdir(evalPath)):\n",
    "            os.makedirs(evalPath)\n",
    "\n",
    "        pickle.dump(evaluations,\n",
    "                    open(os.path.join(evalPath, \"{}fold_evaluations.pickle\".format(n_fold)), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Add import statement here, to make this next part of code standalone executable\n",
    "##################################################################################\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##### Load file and convert to dataframe for easy manipulation\n",
    "##################################################################################\n",
    "\n",
    "evalPath = os.path.join(outPath, expName, \"_Evaluation_All_Datasets\")\n",
    "if(not os.path.isdir(evalPath)):\n",
    "    os.makedirs(evalPath)\n",
    "\n",
    "evaluations = pickle.load(open(os.path.join(evalPath, \"{}fold_evaluations.pickle\".format(n_fold)), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluations[\"Model\"] = evaluations[\"Model\"][0:20]\n",
    "# evaluations_df = pd.DataFrame.from_dict(evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations_df = pd.DataFrame.from_dict(evaluations)\n",
    "\n",
    "##################################################################################\n",
    "##### Group dataset (mean of metrics) by [Dataset, Model, Train_Test] combinations\n",
    "##################################################################################\n",
    "\n",
    "evaluations_df_grouped = evaluations_df.groupby([\"Dataset\", \n",
    "                                                 \"Model\", \n",
    "                                                 \"Train_Test\"]).mean().filter(['Accuracy', \n",
    "                                                                               'Precision', \n",
    "                                                                               'AUC', \n",
    "                                                                               'Sensitivity', \n",
    "                                                                               'Specificity', \n",
    "                                                                               'MCC'])\n",
    "\n",
    "# DLNN_3 = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(1), ['DLNN_3'])]\n",
    "# DLNN_5 = evaluations_df_grouped[np.in1d(evaluations_df_grouped.index.get_level_values(1), ['DLNN_5'])]\n",
    "\n",
    "# DLNN_3_Train = DLNN_3[np.in1d(DLNN_3.index.get_level_values(2), ['Train'])]\n",
    "# DLNN_3_Test = DLNN_3[np.in1d(DLNN_3.index.get_level_values(2), ['Test'])]\n",
    "\n",
    "# DLNN_5_Train = DLNN_5[np.in1d(DLNN_5.index.get_level_values(2), ['Train'])]\n",
    "# DLNN_5_Test = DLNN_5[np.in1d(DLNN_5.index.get_level_values(2), ['Test'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">HS_990</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">HS_990</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.542424</td>\n",
       "      <td>0.532827</td>\n",
       "      <td>0.565122</td>\n",
       "      <td>0.563250</td>\n",
       "      <td>0.532827</td>\n",
       "      <td>0.090050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train</td>\n",
       "      <td>0.876543</td>\n",
       "      <td>0.802278</td>\n",
       "      <td>0.941823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.802278</td>\n",
       "      <td>0.777281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">MM_944</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">MM_944</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.632408</td>\n",
       "      <td>0.607860</td>\n",
       "      <td>0.674880</td>\n",
       "      <td>0.675229</td>\n",
       "      <td>0.607860</td>\n",
       "      <td>0.273827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train</td>\n",
       "      <td>0.905367</td>\n",
       "      <td>0.841036</td>\n",
       "      <td>0.957713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.841036</td>\n",
       "      <td>0.825740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">SN_628</td>\n",
       "      <td rowspan=\"2\" valign=\"top\">SN_628</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.581234</td>\n",
       "      <td>0.572457</td>\n",
       "      <td>0.638237</td>\n",
       "      <td>0.595605</td>\n",
       "      <td>0.572457</td>\n",
       "      <td>0.165305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train</td>\n",
       "      <td>0.895616</td>\n",
       "      <td>0.827553</td>\n",
       "      <td>0.962793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827553</td>\n",
       "      <td>0.809172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Accuracy  Precision       AUC  Sensitivity  \\\n",
       "Dataset Model  Train_Test                                               \n",
       "HS_990  HS_990 Test        0.542424   0.532827  0.565122     0.563250   \n",
       "               Train       0.876543   0.802278  0.941823     1.000000   \n",
       "MM_944  MM_944 Test        0.632408   0.607860  0.674880     0.675229   \n",
       "               Train       0.905367   0.841036  0.957713     1.000000   \n",
       "SN_628  SN_628 Test        0.581234   0.572457  0.638237     0.595605   \n",
       "               Train       0.895616   0.827553  0.962793     1.000000   \n",
       "\n",
       "                           Specificity       MCC  \n",
       "Dataset Model  Train_Test                         \n",
       "HS_990  HS_990 Test           0.532827  0.090050  \n",
       "               Train          0.802278  0.777281  \n",
       "MM_944  MM_944 Test           0.607860  0.273827  \n",
       "               Train          0.841036  0.825740  \n",
       "SN_628  SN_628 Test           0.572457  0.165305  \n",
       "               Train          0.827553  0.809172  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# ##### Decide on metric to visualize\n",
    "# ##################################################################################\n",
    "\n",
    "# print(\"Metrics Available : \")\n",
    "# print(list(evaluations_df_grouped.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select a metric to plot below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_to_plot = \"Accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# ##### Visualize with a multiple Bar chart\n",
    "# ##################################################################################\n",
    "\n",
    "# x = np.arange(len(DLNN_3_Train[metric_to_plot]))\n",
    "# width = 0.15\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(17,6))\n",
    "# rects1 = ax.bar(x - (4*(width/2)), round(DLNN_3_Train[metric_to_plot]*100, 3), width, label='DLNN_3, Train')\n",
    "# rects2 = ax.bar(x - (1.5*(width/2)), round(DLNN_5_Train[metric_to_plot]*100, 3), width, label='DLNN_5, Train')\n",
    "# rects3 = ax.bar(x + (1.5*(width/2)), round(DLNN_3_Test[metric_to_plot]*100, 3), width, label='DLNN_3, Test')\n",
    "# rects4 = ax.bar(x + (4*(width/2)), round(DLNN_5_Test[metric_to_plot]*100, 3), width, label='DLNN_5, Test')\n",
    "\n",
    "# ## Custom y-axis tick labels\n",
    "# ax.set_ylabel(metric_to_plot)\n",
    "# ax.set_ylim([(math.floor(min(evaluations_df_grouped[metric_to_plot])*10)-1)*10, \n",
    "#             (math.ceil(max(evaluations_df_grouped[metric_to_plot])*10)+1)*10])\n",
    "# # ax.set_ylim([80, 105])\n",
    "\n",
    "# ## Custom x-axis tick labels\n",
    "# ax.set_xticks(x)\n",
    "# # ax.set_xticklabels(DLNN_3_Train.index.get_level_values(0))\n",
    "# # ax.set_xticklabels([m+\" - \"+str(n) for m,n in \n",
    "# #                         zip(DLNN_3_Train.index.get_level_values(0),DLNN_3_Train.index.get_level_values(1))],\n",
    "# #                   rotation=30)\n",
    "# ax.set_xticklabels(DLNN_3_Train.index.get_level_values(0))\n",
    "\n",
    "# ax.set_title(metric_to_plot+' by Dataset, Model, Train/Test')\n",
    "# ax.legend(loc='upper left')\n",
    "\n",
    "# def autolabel(rects):\n",
    "#     for rect in rects:\n",
    "#         height = rect.get_height()\n",
    "#         ax.annotate('{}'.format(height),\n",
    "#                     xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "#                     xytext=(0, 3),  # 3 points vertical offset\n",
    "#                     textcoords=\"offset points\", \n",
    "#                     ha='center', va='bottom', rotation=90)\n",
    "\n",
    "# autolabel(rects1)\n",
    "# autolabel(rects2)\n",
    "# autolabel(rects3)\n",
    "# autolabel(rects4)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store all metrics' plots to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# ##### Iteratively generate comparison plot using every metric\n",
    "# ##################################################################################\n",
    "\n",
    "# for metric_to_plot in list(evaluations_df_grouped.columns):\n",
    "    \n",
    "#     x = np.arange(len(DLNN_3_Train[metric_to_plot]))\n",
    "#     width = 0.15\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(17,6))\n",
    "#     rects1 = ax.bar(x - (4*(width/2)), round(DLNN_3_Train[metric_to_plot]*100, 3), width, label='DLNN_3, Train')\n",
    "#     rects2 = ax.bar(x - (1.5*(width/2)), round(DLNN_5_Train[metric_to_plot]*100, 3), width, label='DLNN_5, Train')\n",
    "#     rects3 = ax.bar(x + (1.5*(width/2)), round(DLNN_3_Test[metric_to_plot]*100, 3), width, label='DLNN_3, Test')\n",
    "#     rects4 = ax.bar(x + (4*(width/2)), round(DLNN_5_Test[metric_to_plot]*100, 3), width, label='DLNN_5, Test')\n",
    "\n",
    "#     ## Custom y-axis tick labels\n",
    "#     ax.set_ylabel(metric_to_plot)\n",
    "#     ax.set_ylim([(math.floor(min(evaluations_df_grouped[metric_to_plot])*10)-1)*10, \n",
    "#                 (math.ceil(max(evaluations_df_grouped[metric_to_plot])*10)+1)*10])\n",
    "#     # ax.set_ylim([80, 105])\n",
    "\n",
    "#     ## Custom x-axis tick labels\n",
    "#     ax.set_xticks(x)\n",
    "#     # ax.set_xticklabels(DLNN_3_Train.index.get_level_values(0))\n",
    "#     # ax.set_xticklabels([m+\" - \"+str(n) for m,n in \n",
    "#     #                         zip(DLNN_3_Train.index.get_level_values(0),DLNN_3_Train.index.get_level_values(1))],\n",
    "#     #                   rotation=30)\n",
    "#     ax.set_xticklabels(DLNN_3_Train.index.get_level_values(0))\n",
    "\n",
    "#     ax.set_title(metric_to_plot+' by Dataset, Model, Train/Test')\n",
    "#     ax.legend(loc='upper left')\n",
    "\n",
    "#     def autolabel(rects):\n",
    "#         for rect in rects:\n",
    "#             height = rect.get_height()\n",
    "#             ax.annotate('{}'.format(height),\n",
    "#                         xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "#                         xytext=(0, 3),  # 3 points vertical offset\n",
    "#                         textcoords=\"offset points\", \n",
    "#                         ha='center', va='bottom', rotation=90)\n",
    "\n",
    "#     autolabel(rects1)\n",
    "#     autolabel(rects2)\n",
    "#     autolabel(rects3)\n",
    "#     autolabel(rects4)\n",
    "    \n",
    "#     plt.savefig(os.path.join(evalPath, \"{}_DLNN_Comparison\".format(metric_to_plot)))\n",
    "#     plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
